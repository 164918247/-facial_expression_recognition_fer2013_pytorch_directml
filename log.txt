Namespace(batch_size=24, device='dml', epochs=200, learning_rate=0.03, model='resnet18', momentum=0.9, accumulation_steps=2, path='fer2013.csv', save_model=True, weight_decay=0.0001)
Loading thedataset from: D:\Project\FacialExpression\data\fer2013.csv
Weight List has been produced
	Train data X [BatchSize, NCrop, C, H, W]: 
		shape=torch.Size([24, 5, 1, 40, 40]), 
		dtype=torch.float32
	Train data Y: 
		shape=torch.Size([24]), 
		dtype=torch.int64
The num of each class: [3995, 436, 4097, 7215, 4830, 3171, 4965]
Loading thedataset from: D:\Project\FacialExpression\data\fer2013.csv
Weight List has been produced
	Val data X [BatchSize, NCrop, C, H, W]: 
		shape=torch.Size([24, 10, 1, 40, 40]), 
		dtype=torch.float32
	Val data Y: 
		shape=torch.Size([24]), 
		dtype=torch.int64
The num of each class: [467, 56, 496, 895, 653, 415, 607]
Loading thedataset from: D:\Project\FacialExpression\data\fer2013.csv
Weight List has been produced
	Test data X [BatchSize, NCrop, C, H, W]: 
		shape=torch.Size([24, 10, 1, 40, 40]), 
		dtype=torch.float32
	Test data Y: 
		shape=torch.Size([24]), 
		dtype=torch.int64
The num of each class: [491, 55, 528, 879, 594, 416, 626]
Finished moving resnet18 to device: dml in 0.0s.

Epoch 1, Learning Rate [0.03]
-------------------------------
Loss: 0.939672 | Acc: 23.81% [  8571.35/ 36000] | Train [ 7200/28709] in 57.398595s
Loss: 0.924492 | Acc: 24.14% [ 17380.43/ 72000] | Train [14400/28709] in 57.525787s
Loss: 0.918418 | Acc: 24.47% [ 26423.46/108000] | Train [21600/28709] in 57.311345s
Loss: 0.914030 | Acc: 24.70% [ 35460.84/143545] | Train [28709/28709] in 56.823769s
Val Error: Acc 27.2% | Avg loss: 1.773775 in 19.096759s
Test Error: Acc 27.0% | Avg loss: 1.777734 in 19.478923s
current highest Acc: 27.2%

Epoch 2, Learning Rate [0.029998149487224908]
-------------------------------
Loss: 0.898342 | Acc: 25.96% [  9344.44/ 36000] | Train [ 7200/28709] in 57.600945s
Loss: 0.895480 | Acc: 26.47% [ 19059.94/ 72000] | Train [14400/28709] in 57.235666s
Loss: 0.892453 | Acc: 27.01% [ 29170.24/108000] | Train [21600/28709] in 57.239450s
Loss: 0.888014 | Acc: 27.73% [ 39803.91/143545] | Train [28709/28709] in 56.670707s
Val Error: Acc 40.9% | Avg loss: 1.604230 in 18.891822s
Test Error: Acc 39.9% | Avg loss: 1.611134 in 18.872018s
current highest Acc: 40.9%

Epoch 3, Learning Rate [0.029992598405485973]
-------------------------------
Loss: 0.860600 | Acc: 31.67% [ 11400.19/ 36000] | Train [ 7200/28709] in 57.138111s
Loss: 0.857566 | Acc: 32.44% [ 23356.16/ 72000] | Train [14400/28709] in 57.242017s
Loss: 0.852808 | Acc: 33.31% [ 35974.68/108000] | Train [21600/28709] in 57.264824s
Loss: 0.848261 | Acc: 34.07% [ 48908.31/143545] | Train [28709/28709] in 56.671856s
Val Error: Acc 50.4% | Avg loss: 1.456777 in 18.884481s
Test Error: Acc 49.1% | Avg loss: 1.453731 in 18.898919s
current highest Acc: 50.4%

Epoch 4, Learning Rate [0.029983348124429553]
-------------------------------
Loss: 0.826141 | Acc: 37.86% [ 13629.14/ 36000] | Train [ 7200/28709] in 57.127052s
Loss: 0.822463 | Acc: 38.36% [ 27618.81/ 72000] | Train [14400/28709] in 57.485524s
Loss: 0.821832 | Acc: 38.34% [ 41405.75/108000] | Train [21600/28709] in 58.173140s
Loss: 0.819347 | Acc: 38.61% [ 55425.87/143545] | Train [28709/28709] in 56.611009s
Val Error: Acc 52.5% | Avg loss: 1.409085 in 19.135973s
Test Error: Acc 54.4% | Avg loss: 1.389665 in 19.146028s
current highest Acc: 52.5%

Epoch 5, Learning Rate [0.029970400926424078]
-------------------------------
Loss: 0.805914 | Acc: 40.53% [ 14590.83/ 36000] | Train [ 7200/28709] in 57.052123s
Loss: 0.804412 | Acc: 40.81% [ 29386.42/ 72000] | Train [14400/28709] in 57.174201s
Loss: 0.803277 | Acc: 40.92% [ 44192.68/108000] | Train [21600/28709] in 57.191326s
Loss: 0.803619 | Acc: 40.97% [ 58815.57/143545] | Train [28709/28709] in 56.599449s
Val Error: Acc 54.3% | Avg loss: 1.368964 in 19.153644s
Test Error: Acc 55.9% | Avg loss: 1.346301 in 19.135111s
current highest Acc: 54.3%

Epoch 6, Learning Rate [0.029953760005996925]
-------------------------------
Loss: 0.784844 | Acc: 43.57% [ 15684.92/ 36000] | Train [ 7200/28709] in 57.064352s
Loss: 0.785812 | Acc: 43.38% [ 31234.66/ 72000] | Train [14400/28709] in 57.157852s
Loss: 0.786858 | Acc: 43.28% [ 46741.64/108000] | Train [21600/28709] in 57.185786s
Loss: 0.788296 | Acc: 42.92% [ 61610.42/143545] | Train [28709/28709] in 56.587720s
Val Error: Acc 56.1% | Avg loss: 1.333415 in 19.137584s
Test Error: Acc 56.5% | Avg loss: 1.319620 in 19.149078s
current highest Acc: 56.1%

Epoch 7, Learning Rate [0.029933429469046202]
-------------------------------
Loss: 0.789277 | Acc: 42.74% [ 15387.79/ 36000] | Train [ 7200/28709] in 57.047680s
Loss: 0.785232 | Acc: 43.19% [ 31098.99/ 72000] | Train [14400/28709] in 57.177038s
Loss: 0.785638 | Acc: 43.22% [ 46675.42/108000] | Train [21600/28709] in 57.183405s
Loss: 0.783700 | Acc: 43.46% [ 62391.08/143545] | Train [28709/28709] in 56.598077s
Val Error: Acc 54.9% | Avg loss: 1.337634 in 19.130147s
Test Error: Acc 56.1% | Avg loss: 1.318067 in 19.146743s

Epoch 8, Learning Rate [0.0299094143318277]
-------------------------------
Loss: 0.776962 | Acc: 44.33% [ 15959.59/ 36000] | Train [ 7200/28709] in 57.051223s
Loss: 0.777545 | Acc: 44.30% [ 31896.37/ 72000] | Train [14400/28709] in 57.170094s
Loss: 0.776389 | Acc: 44.35% [ 47899.29/108000] | Train [21600/28709] in 57.179090s
Loss: 0.776574 | Acc: 44.37% [ 63684.59/143545] | Train [28709/28709] in 56.595671s
Val Error: Acc 59.1% | Avg loss: 1.286922 in 19.122318s
Test Error: Acc 60.4% | Avg loss: 1.274276 in 19.126698s
current highest Acc: 59.1%

Epoch 9, Learning Rate [0.029881720519717173]
-------------------------------
Loss: 0.771360 | Acc: 44.90% [ 16163.91/ 36000] | Train [ 7200/28709] in 57.048130s
Loss: 0.775097 | Acc: 44.40% [ 31968.37/ 72000] | Train [14400/28709] in 57.169930s
Loss: 0.773057 | Acc: 44.79% [ 48371.98/108000] | Train [21600/28709] in 57.179346s
Loss: 0.772695 | Acc: 44.76% [ 64255.85/143545] | Train [28709/28709] in 56.593648s
Val Error: Acc 59.7% | Avg loss: 1.274313 in 19.140813s
Test Error: Acc 60.2% | Avg loss: 1.260926 in 19.136923s
current highest Acc: 59.7%

Epoch 10, Learning Rate [0.029850354865748364]
-------------------------------
Loss: 0.770534 | Acc: 45.03% [ 16209.80/ 36000] | Train [ 7200/28709] in 57.054863s
Loss: 0.768179 | Acc: 45.30% [ 32613.16/ 72000] | Train [14400/28709] in 57.163355s
Loss: 0.764775 | Acc: 45.85% [ 49520.13/108000] | Train [21600/28709] in 57.175263s
Loss: 0.766790 | Acc: 45.60% [ 65453.69/143545] | Train [28709/28709] in 56.591894s
Val Error: Acc 59.5% | Avg loss: 1.263398 in 19.122582s
Test Error: Acc 59.5% | Avg loss: 1.255411 in 19.135745s

Epoch 11, Learning Rate [0.02981532510892707]
-------------------------------
Loss: 0.761822 | Acc: 46.11% [ 16599.78/ 36000] | Train [ 7200/28709] in 57.033990s
Loss: 0.760967 | Acc: 46.33% [ 33355.94/ 72000] | Train [14400/28709] in 57.148103s
Loss: 0.760403 | Acc: 46.38% [ 50092.53/108000] | Train [21600/28709] in 57.156316s
Loss: 0.760711 | Acc: 46.39% [ 66585.88/143545] | Train [28709/28709] in 56.566676s
Val Error: Acc 61.4% | Avg loss: 1.225940 in 19.134714s
Test Error: Acc 61.9% | Avg loss: 1.208069 in 19.176834s
current highest Acc: 61.4%

Epoch 12, Learning Rate [0.02977663989232161]
-------------------------------
Loss: 0.761828 | Acc: 46.06% [ 16583.32/ 36000] | Train [ 7200/28709] in 57.061070s
Loss: 0.761397 | Acc: 46.31% [ 33341.86/ 72000] | Train [14400/28709] in 57.178647s
Loss: 0.759530 | Acc: 46.54% [ 50264.23/108000] | Train [21600/28709] in 57.158557s
Loss: 0.759533 | Acc: 46.50% [ 66745.16/143545] | Train [28709/28709] in 56.576346s
Val Error: Acc 61.6% | Avg loss: 1.221941 in 19.134667s
Test Error: Acc 62.6% | Avg loss: 1.200216 in 19.153804s
current highest Acc: 61.6%

Epoch 13, Learning Rate [0.029734308760930334]
-------------------------------
Loss: 0.757419 | Acc: 46.78% [ 16840.24/ 36000] | Train [ 7200/28709] in 57.051482s
Loss: 0.754646 | Acc: 46.97% [ 33816.45/ 72000] | Train [14400/28709] in 57.163093s
Loss: 0.755292 | Acc: 46.90% [ 50655.99/108000] | Train [21600/28709] in 57.177996s
Loss: 0.755398 | Acc: 47.01% [ 67476.03/143545] | Train [28709/28709] in 56.575863s
Val Error: Acc 60.5% | Avg loss: 1.258365 in 19.127073s
Test Error: Acc 60.7% | Avg loss: 1.239376 in 19.139199s

Epoch 14, Learning Rate [0.02968834215932649]
-------------------------------
Loss: 0.753618 | Acc: 47.23% [ 17001.68/ 36000] | Train [ 7200/28709] in 57.050212s
Loss: 0.753524 | Acc: 47.21% [ 33992.92/ 72000] | Train [14400/28709] in 57.164021s
Loss: 0.754307 | Acc: 47.07% [ 50840.58/108000] | Train [21600/28709] in 57.176674s
Loss: 0.752284 | Acc: 47.31% [ 67916.14/143545] | Train [28709/28709] in 56.572780s
Val Error: Acc 61.0% | Avg loss: 1.237445 in 19.138938s
Test Error: Acc 62.2% | Avg loss: 1.214718 in 19.132440s

Epoch 15, Learning Rate [0.029638751429081216]
-------------------------------
Loss: 0.752292 | Acc: 47.31% [ 17032.72/ 36000] | Train [ 7200/28709] in 57.044088s
Loss: 0.749513 | Acc: 47.58% [ 34254.72/ 72000] | Train [14400/28709] in 57.182623s
Loss: 0.750083 | Acc: 47.55% [ 51351.72/108000] | Train [21600/28709] in 57.173015s
Loss: 0.750584 | Acc: 47.54% [ 68242.84/143545] | Train [28709/28709] in 56.566025s
Val Error: Acc 62.4% | Avg loss: 1.233828 in 19.139406s
Test Error: Acc 64.1% | Avg loss: 1.213359 in 19.144226s
current highest Acc: 62.4%

Epoch 16, Learning Rate [0.029585548805965152]
-------------------------------
Loss: 0.743789 | Acc: 48.63% [ 17508.04/ 36000] | Train [ 7200/28709] in 57.045048s
Loss: 0.743803 | Acc: 48.53% [ 34942.97/ 72000] | Train [14400/28709] in 57.160307s
Loss: 0.742378 | Acc: 48.66% [ 52548.91/108000] | Train [21600/28709] in 57.163139s
Loss: 0.743651 | Acc: 48.47% [ 69574.88/143545] | Train [28709/28709] in 56.573277s
Val Error: Acc 63.2% | Avg loss: 1.206001 in 19.131934s
Test Error: Acc 64.1% | Avg loss: 1.188871 in 19.133274s
current highest Acc: 63.2%

Epoch 17, Learning Rate [0.029528747416929468]
-------------------------------
Loss: 0.748881 | Acc: 47.85% [ 17226.48/ 36000] | Train [ 7200/28709] in 57.052824s
Loss: 0.751265 | Acc: 47.49% [ 34189.46/ 72000] | Train [14400/28709] in 57.169338s
Loss: 0.748540 | Acc: 47.87% [ 51699.48/108000] | Train [21600/28709] in 57.165381s
Loss: 0.748217 | Acc: 47.96% [ 68845.30/143545] | Train [28709/28709] in 56.568577s
Val Error: Acc 63.1% | Avg loss: 1.245015 in 19.137699s
Test Error: Acc 63.8% | Avg loss: 1.231147 in 19.156336s

Epoch 18, Learning Rate [0.029468361276866976]
-------------------------------
Loss: 0.740798 | Acc: 48.49% [ 17455.01/ 36000] | Train [ 7200/28709] in 57.039564s
Loss: 0.744230 | Acc: 48.30% [ 34777.28/ 72000] | Train [14400/28709] in 57.140953s
Loss: 0.742763 | Acc: 48.63% [ 52519.26/108000] | Train [21600/28709] in 57.153658s
Loss: 0.741869 | Acc: 48.76% [ 69992.18/143545] | Train [28709/28709] in 56.568078s
Val Error: Acc 62.4% | Avg loss: 1.228525 in 19.128340s
Test Error: Acc 63.2% | Avg loss: 1.209882 in 19.132341s

Epoch 19, Learning Rate [0.029404405285154152]
-------------------------------
Loss: 0.744868 | Acc: 48.49% [ 17454.69/ 36000] | Train [ 7200/28709] in 57.034761s
Loss: 0.740081 | Acc: 48.91% [ 35217.76/ 72000] | Train [14400/28709] in 57.151745s
Loss: 0.741089 | Acc: 48.78% [ 52686.72/108000] | Train [21600/28709] in 57.148341s
Loss: 0.740549 | Acc: 48.77% [ 70001.68/143545] | Train [28709/28709] in 56.555907s
Val Error: Acc 63.5% | Avg loss: 1.177412 in 19.140866s
Test Error: Acc 64.9% | Avg loss: 1.156271 in 19.140331s
current highest Acc: 63.5%

Epoch 20, Learning Rate [0.029336895221974957]
-------------------------------
Loss: 0.733870 | Acc: 49.99% [ 17998.20/ 36000] | Train [ 7200/28709] in 57.049248s
Loss: 0.734780 | Acc: 49.68% [ 35768.31/ 72000] | Train [14400/28709] in 57.157907s
Loss: 0.735198 | Acc: 49.61% [ 53577.67/108000] | Train [21600/28709] in 57.157573s
Loss: 0.736318 | Acc: 49.47% [ 71017.01/143545] | Train [28709/28709] in 56.563732s
Val Error: Acc 63.6% | Avg loss: 1.190877 in 19.139123s
Test Error: Acc 63.7% | Avg loss: 1.180566 in 19.138388s
current highest Acc: 63.6%

Epoch 21, Learning Rate [0.029265847744427313]
-------------------------------
Loss: 0.738716 | Acc: 49.42% [ 17789.41/ 36000] | Train [ 7200/28709] in 57.032603s
Loss: 0.737182 | Acc: 49.52% [ 35653.67/ 72000] | Train [14400/28709] in 57.152720s
Loss: 0.737509 | Acc: 49.38% [ 53332.85/108000] | Train [21600/28709] in 57.156193s
Loss: 0.738455 | Acc: 49.24% [ 70680.37/143545] | Train [28709/28709] in 56.565720s
Val Error: Acc 63.6% | Avg loss: 1.196134 in 19.144012s
Test Error: Acc 64.4% | Avg loss: 1.175041 in 19.125252s

Epoch 22, Learning Rate [0.029191280382413188]
-------------------------------
Loss: 0.730234 | Acc: 49.51% [ 17823.88/ 36000] | Train [ 7200/28709] in 57.035766s
Loss: 0.732859 | Acc: 49.59% [ 35702.77/ 72000] | Train [14400/28709] in 57.143787s
Loss: 0.730702 | Acc: 49.89% [ 53885.47/108000] | Train [21600/28709] in 57.141288s
Loss: 0.729787 | Acc: 50.03% [ 71811.07/143545] | Train [28709/28709] in 56.553249s
Val Error: Acc 65.1% | Avg loss: 1.176911 in 19.146312s
Test Error: Acc 65.7% | Avg loss: 1.165995 in 19.132548s
current highest Acc: 65.1%

Epoch 23, Learning Rate [0.02911321153431339]
-------------------------------
Loss: 0.732572 | Acc: 49.78% [ 17920.10/ 36000] | Train [ 7200/28709] in 57.031657s
Loss: 0.731022 | Acc: 49.90% [ 35930.48/ 72000] | Train [14400/28709] in 57.135737s
Loss: 0.732564 | Acc: 49.70% [ 53675.52/108000] | Train [21600/28709] in 57.145093s
Loss: 0.732438 | Acc: 49.74% [ 71398.19/143545] | Train [28709/28709] in 56.545715s
Val Error: Acc 65.3% | Avg loss: 1.161804 in 19.137930s
Test Error: Acc 65.4% | Avg loss: 1.146557 in 19.133497s
current highest Acc: 65.3%

Epoch 24, Learning Rate [0.029031660462448018]
-------------------------------
Loss: 0.729327 | Acc: 50.41% [ 18148.80/ 36000] | Train [ 7200/28709] in 57.018206s
Loss: 0.732764 | Acc: 49.94% [ 35959.69/ 72000] | Train [14400/28709] in 57.137772s
Loss: 0.732519 | Acc: 49.91% [ 53903.08/108000] | Train [21600/28709] in 57.142606s
Loss: 0.732885 | Acc: 49.90% [ 71632.36/143545] | Train [28709/28709] in 56.545683s
Val Error: Acc 65.3% | Avg loss: 1.162843 in 19.130187s
Test Error: Acc 66.4% | Avg loss: 1.141298 in 19.138335s

Epoch 25, Learning Rate [0.028946647288323777]
-------------------------------
Loss: 0.722315 | Acc: 51.26% [ 18455.24/ 36000] | Train [ 7200/28709] in 57.023559s
Loss: 0.722821 | Acc: 51.15% [ 36827.10/ 72000] | Train [14400/28709] in 57.130253s
Loss: 0.724987 | Acc: 50.85% [ 54919.89/108000] | Train [21600/28709] in 57.139883s
Loss: 0.727032 | Acc: 50.51% [ 72507.72/143545] | Train [28709/28709] in 56.543256s
Val Error: Acc 65.1% | Avg loss: 1.174406 in 19.105867s
Test Error: Acc 65.6% | Avg loss: 1.150863 in 19.148328s

Epoch 26, Learning Rate [0.028858192987669305]
-------------------------------
Loss: 0.727812 | Acc: 50.50% [ 18180.65/ 36000] | Train [ 7200/28709] in 57.014283s
Loss: 0.725620 | Acc: 50.75% [ 36542.36/ 72000] | Train [14400/28709] in 57.125953s
Loss: 0.724355 | Acc: 50.78% [ 54844.30/108000] | Train [21600/28709] in 57.145035s
Loss: 0.724577 | Acc: 50.74% [ 72833.31/143545] | Train [28709/28709] in 56.554006s
Val Error: Acc 66.0% | Avg loss: 1.139321 in 19.124039s
Test Error: Acc 66.9% | Avg loss: 1.120856 in 19.137468s
current highest Acc: 66.0%

Epoch 27, Learning Rate [0.02876631938525972]
-------------------------------
Loss: 0.730833 | Acc: 50.26% [ 18094.65/ 36000] | Train [ 7200/28709] in 57.029280s
Loss: 0.731005 | Acc: 50.26% [ 36189.60/ 72000] | Train [14400/28709] in 57.137695s
Loss: 0.729484 | Acc: 50.36% [ 54392.17/108000] | Train [21600/28709] in 57.140760s
Loss: 0.729326 | Acc: 50.36% [ 72286.86/143545] | Train [28709/28709] in 56.548649s
Val Error: Acc 63.8% | Avg loss: 1.182550 in 19.133330s
Test Error: Acc 66.1% | Avg loss: 1.163403 in 19.133931s

Epoch 28, Learning Rate [0.02867104914953168]
-------------------------------
Loss: 0.724421 | Acc: 50.74% [ 18266.13/ 36000] | Train [ 7200/28709] in 57.031643s
Loss: 0.726671 | Acc: 50.55% [ 36393.58/ 72000] | Train [14400/28709] in 57.131823s
Loss: 0.727030 | Acc: 50.50% [ 54543.35/108000] | Train [21600/28709] in 57.142217s
Loss: 0.727204 | Acc: 50.49% [ 72472.27/143545] | Train [28709/28709] in 56.579558s
Val Error: Acc 66.0% | Avg loss: 1.148546 in 19.135351s
Test Error: Acc 67.2% | Avg loss: 1.136628 in 19.130690s
current highest Acc: 66.0%

Epoch 29, Learning Rate [0.028572405786990294]
-------------------------------
Loss: 0.713581 | Acc: 52.00% [ 18718.56/ 36000] | Train [ 7200/28709] in 57.034974s
Loss: 0.719000 | Acc: 51.33% [ 36954.79/ 72000] | Train [14400/28709] in 57.147031s
Loss: 0.719338 | Acc: 51.26% [ 55357.69/108000] | Train [21600/28709] in 57.142242s
Loss: 0.719023 | Acc: 51.25% [ 73569.59/143545] | Train [28709/28709] in 56.555618s
Val Error: Acc 65.4% | Avg loss: 1.147989 in 19.139464s
Test Error: Acc 66.8% | Avg loss: 1.133637 in 19.149037s

Epoch 30, Learning Rate [0.028470413636409234]
-------------------------------
Loss: 0.720018 | Acc: 51.03% [ 18370.56/ 36000] | Train [ 7200/28709] in 57.025297s
Loss: 0.719256 | Acc: 51.24% [ 36889.46/ 72000] | Train [14400/28709] in 57.141457s
Loss: 0.719376 | Acc: 51.34% [ 55448.21/108000] | Train [21600/28709] in 57.134189s
Loss: 0.720804 | Acc: 51.14% [ 73401.80/143545] | Train [28709/28709] in 56.540654s
Val Error: Acc 65.6% | Avg loss: 1.152359 in 19.141243s
Test Error: Acc 65.8% | Avg loss: 1.140026 in 19.152563s

Epoch 31, Learning Rate [0.028365097862825518]
-------------------------------
Loss: 0.713634 | Acc: 51.79% [ 18643.20/ 36000] | Train [ 7200/28709] in 57.045451s
Loss: 0.711295 | Acc: 52.21% [ 37587.71/ 72000] | Train [14400/28709] in 57.179550s
Loss: 0.714761 | Acc: 51.88% [ 56035.39/108000] | Train [21600/28709] in 57.153158s
Loss: 0.716257 | Acc: 51.73% [ 74258.59/143545] | Train [28709/28709] in 56.537109s
Val Error: Acc 66.2% | Avg loss: 1.141762 in 19.129305s
Test Error: Acc 66.9% | Avg loss: 1.121658 in 19.141148s
current highest Acc: 66.2%

Epoch 32, Learning Rate [0.028256484451330405]
-------------------------------
Loss: 0.715159 | Acc: 51.95% [ 18701.12/ 36000] | Train [ 7200/28709] in 57.022165s
Loss: 0.719806 | Acc: 51.47% [ 37055.34/ 72000] | Train [14400/28709] in 57.132179s
Loss: 0.718780 | Acc: 51.70% [ 55841.36/108000] | Train [21600/28709] in 57.140670s
Loss: 0.720123 | Acc: 51.53% [ 73969.88/143545] | Train [28709/28709] in 56.530877s
Val Error: Acc 66.7% | Avg loss: 1.126167 in 19.130678s
Test Error: Acc 68.0% | Avg loss: 1.105751 in 19.136395s
current highest Acc: 66.7%

Epoch 33, Learning Rate [0.028144600200657954]
-------------------------------
Loss: 0.716997 | Acc: 52.11% [ 18760.56/ 36000] | Train [ 7200/28709] in 57.029598s
Loss: 0.721884 | Acc: 51.42% [ 37021.98/ 72000] | Train [14400/28709] in 57.125455s
Loss: 0.719801 | Acc: 51.64% [ 55768.73/108000] | Train [21600/28709] in 57.144388s
Loss: 0.720564 | Acc: 51.51% [ 73944.61/143545] | Train [28709/28709] in 56.550122s
Val Error: Acc 66.6% | Avg loss: 1.142327 in 19.137250s
Test Error: Acc 68.1% | Avg loss: 1.120741 in 19.130112s

Epoch 34, Learning Rate [0.02802947271657287]
-------------------------------
Loss: 0.715647 | Acc: 51.94% [ 18699.96/ 36000] | Train [ 7200/28709] in 57.028568s
Loss: 0.711234 | Acc: 52.41% [ 37733.95/ 72000] | Train [14400/28709] in 57.145105s
Loss: 0.714012 | Acc: 52.12% [ 56292.89/108000] | Train [21600/28709] in 57.141489s
Loss: 0.713257 | Acc: 52.21% [ 74939.28/143545] | Train [28709/28709] in 56.540723s
Val Error: Acc 66.3% | Avg loss: 1.142487 in 19.136288s
Test Error: Acc 67.6% | Avg loss: 1.126114 in 19.130076s

Epoch 35, Learning Rate [0.027911130405059156]
-------------------------------
Loss: 0.709467 | Acc: 52.58% [ 18928.83/ 36000] | Train [ 7200/28709] in 57.011386s
Loss: 0.711456 | Acc: 52.22% [ 37599.47/ 72000] | Train [14400/28709] in 57.124291s
Loss: 0.708711 | Acc: 52.57% [ 56779.74/108000] | Train [21600/28709] in 57.129041s
Loss: 0.710180 | Acc: 52.46% [ 75301.95/143545] | Train [28709/28709] in 56.533179s
Val Error: Acc 66.0% | Avg loss: 1.151092 in 19.147837s
Test Error: Acc 67.8% | Avg loss: 1.122481 in 19.129925s

Epoch 36, Learning Rate [0.027789602465311383]
-------------------------------
Loss: 0.719245 | Acc: 51.49% [ 18535.23/ 36000] | Train [ 7200/28709] in 57.016203s
Loss: 0.717618 | Acc: 51.76% [ 37268.76/ 72000] | Train [14400/28709] in 57.118222s
Loss: 0.713612 | Acc: 52.23% [ 56411.84/108000] | Train [21600/28709] in 57.122985s
Loss: 0.715389 | Acc: 51.99% [ 74631.64/143545] | Train [28709/28709] in 56.526076s
Val Error: Acc 67.7% | Avg loss: 1.137408 in 19.132507s
Test Error: Acc 68.2% | Avg loss: 1.124926 in 19.118869s
current highest Acc: 67.7%

Epoch 37, Learning Rate [0.027664918882530226]
-------------------------------
Loss: 0.706683 | Acc: 53.02% [ 19088.81/ 36000] | Train [ 7200/28709] in 57.037488s
Loss: 0.707832 | Acc: 52.78% [ 38004.97/ 72000] | Train [14400/28709] in 57.121391s
Loss: 0.709967 | Acc: 52.59% [ 56800.44/108000] | Train [21600/28709] in 57.130767s
Loss: 0.713447 | Acc: 52.25% [ 74998.98/143545] | Train [28709/28709] in 56.543309s
Val Error: Acc 67.4% | Avg loss: 1.135030 in 19.133571s
Test Error: Acc 68.6% | Avg loss: 1.119721 in 19.110320s

Epoch 38, Learning Rate [0.027537110420524057]
-------------------------------
Loss: 0.712090 | Acc: 51.92% [ 18690.94/ 36000] | Train [ 7200/28709] in 57.012194s
Loss: 0.710495 | Acc: 52.56% [ 37844.72/ 72000] | Train [14400/28709] in 57.120394s
Loss: 0.712155 | Acc: 52.47% [ 56665.75/108000] | Train [21600/28709] in 57.132365s
Loss: 0.711324 | Acc: 52.48% [ 75338.09/143545] | Train [28709/28709] in 56.517701s
Val Error: Acc 67.7% | Avg loss: 1.117661 in 19.123180s
Test Error: Acc 68.7% | Avg loss: 1.101133 in 19.132192s
current highest Acc: 67.7%

Epoch 39, Learning Rate [0.027406208614118428]
-------------------------------
Loss: 0.706591 | Acc: 53.10% [ 19115.55/ 36000] | Train [ 7200/28709] in 56.999123s
Loss: 0.709324 | Acc: 52.81% [ 38026.64/ 72000] | Train [14400/28709] in 57.109620s
Loss: 0.705928 | Acc: 53.23% [ 57483.52/108000] | Train [21600/28709] in 57.119243s
Loss: 0.706785 | Acc: 53.08% [ 76192.77/143545] | Train [28709/28709] in 56.514305s
Val Error: Acc 66.8% | Avg loss: 1.120681 in 19.140178s
Test Error: Acc 68.0% | Avg loss: 1.109584 in 19.122935s

Epoch 40, Learning Rate [0.027272245761375352]
-------------------------------
Loss: 0.710080 | Acc: 52.88% [ 19035.89/ 36000] | Train [ 7200/28709] in 57.005747s
Loss: 0.706131 | Acc: 53.16% [ 38273.50/ 72000] | Train [14400/28709] in 57.108736s
Loss: 0.706720 | Acc: 53.02% [ 57256.84/108000] | Train [21600/28709] in 57.112953s
Loss: 0.708206 | Acc: 52.81% [ 75800.33/143545] | Train [28709/28709] in 56.512956s
Val Error: Acc 68.1% | Avg loss: 1.135602 in 19.139395s
Test Error: Acc 69.2% | Avg loss: 1.118208 in 19.122720s
current highest Acc: 68.1%

Epoch 41, Learning Rate [0.027135254915624213]
-------------------------------
Loss: 0.704781 | Acc: 53.41% [ 19229.04/ 36000] | Train [ 7200/28709] in 57.017254s
Loss: 0.705502 | Acc: 53.35% [ 38409.75/ 72000] | Train [14400/28709] in 57.121969s
Loss: 0.704408 | Acc: 53.34% [ 57611.96/108000] | Train [21600/28709] in 57.120796s
Loss: 0.706855 | Acc: 53.02% [ 76107.84/143545] | Train [28709/28709] in 56.532504s
Val Error: Acc 68.4% | Avg loss: 1.114311 in 19.135672s
Test Error: Acc 69.0% | Avg loss: 1.096024 in 19.134547s
current highest Acc: 68.4%

Epoch 42, Learning Rate [0.026995269877306362]
-------------------------------
Loss: 0.705463 | Acc: 52.73% [ 18983.51/ 36000] | Train [ 7200/28709] in 57.021912s
Loss: 0.711667 | Acc: 52.34% [ 37685.93/ 72000] | Train [14400/28709] in 57.155394s
Loss: 0.709675 | Acc: 52.63% [ 56844.40/108000] | Train [21600/28709] in 57.128666s
Loss: 0.710250 | Acc: 52.61% [ 75516.60/143545] | Train [28709/28709] in 56.516968s
Val Error: Acc 68.2% | Avg loss: 1.118534 in 19.120181s
Test Error: Acc 69.4% | Avg loss: 1.097716 in 19.136075s

Epoch 43, Learning Rate [0.026852325185635358]
-------------------------------
Loss: 0.705715 | Acc: 53.21% [ 19154.95/ 36000] | Train [ 7200/28709] in 57.000602s
Loss: 0.706661 | Acc: 53.25% [ 38340.67/ 72000] | Train [14400/28709] in 57.105412s
Loss: 0.705824 | Acc: 53.37% [ 57639.86/108000] | Train [21600/28709] in 57.114961s
Loss: 0.704467 | Acc: 53.41% [ 76669.60/143545] | Train [28709/28709] in 56.521399s
Val Error: Acc 68.2% | Avg loss: 1.099478 in 19.137331s
Test Error: Acc 69.0% | Avg loss: 1.083789 in 19.132806s

Epoch 44, Learning Rate [0.026706456110074946]
-------------------------------
Loss: 0.702972 | Acc: 53.39% [ 19219.06/ 36000] | Train [ 7200/28709] in 56.996696s
Loss: 0.701527 | Acc: 53.48% [ 38508.64/ 72000] | Train [14400/28709] in 57.109834s
Loss: 0.704848 | Acc: 53.26% [ 57516.79/108000] | Train [21600/28709] in 57.120821s
Loss: 0.702880 | Acc: 53.44% [ 76704.85/143545] | Train [28709/28709] in 56.512675s
Val Error: Acc 67.6% | Avg loss: 1.103100 in 19.118181s
Test Error: Acc 69.3% | Avg loss: 1.084714 in 19.134703s

Epoch 45, Learning Rate [0.02655769864163684]
-------------------------------
Loss: 0.700131 | Acc: 53.18% [ 19145.16/ 36000] | Train [ 7200/28709] in 57.045116s
Loss: 0.704928 | Acc: 52.97% [ 38136.08/ 72000] | Train [14400/28709] in 57.148222s
Loss: 0.704310 | Acc: 53.15% [ 57400.40/108000] | Train [21600/28709] in 57.150773s
Loss: 0.703816 | Acc: 53.34% [ 76562.98/143545] | Train [28709/28709] in 56.559851s
Val Error: Acc 68.8% | Avg loss: 1.114014 in 19.150495s
Test Error: Acc 68.9% | Avg loss: 1.107618 in 19.148301s
current highest Acc: 68.8%

Epoch 46, Learning Rate [0.026406089484000465]
-------------------------------
Loss: 0.702518 | Acc: 53.60% [ 19294.76/ 36000] | Train [ 7200/28709] in 56.999992s
Loss: 0.701386 | Acc: 53.77% [ 38715.88/ 72000] | Train [14400/28709] in 57.114161s
Loss: 0.702150 | Acc: 53.67% [ 57964.73/108000] | Train [21600/28709] in 57.123123s
Loss: 0.701084 | Acc: 53.78% [ 77199.49/143545] | Train [28709/28709] in 56.521109s
Val Error: Acc 68.1% | Avg loss: 1.103863 in 19.129293s
Test Error: Acc 69.3% | Avg loss: 1.089210 in 19.140607s

Epoch 47, Learning Rate [0.026251666044456893]
-------------------------------
Loss: 0.698895 | Acc: 54.06% [ 19460.67/ 36000] | Train [ 7200/28709] in 57.001205s
Loss: 0.699804 | Acc: 53.85% [ 38769.55/ 72000] | Train [14400/28709] in 57.109612s
Loss: 0.700759 | Acc: 53.75% [ 58045.36/108000] | Train [21600/28709] in 57.097699s
Loss: 0.699875 | Acc: 53.90% [ 77364.87/143545] | Train [28709/28709] in 56.531393s
Val Error: Acc 68.0% | Avg loss: 1.123672 in 19.112328s
Test Error: Acc 68.4% | Avg loss: 1.108838 in 19.134067s

Epoch 48, Learning Rate [0.026094466424679143]
-------------------------------
Loss: 0.696015 | Acc: 54.37% [ 19573.35/ 36000] | Train [ 7200/28709] in 56.996996s
Loss: 0.694252 | Acc: 54.48% [ 39223.78/ 72000] | Train [14400/28709] in 57.102906s
Loss: 0.696082 | Acc: 54.24% [ 58583.17/108000] | Train [21600/28709] in 57.117552s
Loss: 0.697963 | Acc: 54.11% [ 77670.11/143545] | Train [28709/28709] in 56.520988s
Val Error: Acc 67.4% | Avg loss: 1.125084 in 19.123692s
Test Error: Acc 68.3% | Avg loss: 1.112865 in 19.140433s

Epoch 49, Learning Rate [0.025934529411321173]
-------------------------------
Loss: 0.698658 | Acc: 54.11% [ 19478.19/ 36000] | Train [ 7200/28709] in 57.002346s
Loss: 0.696848 | Acc: 54.40% [ 39166.67/ 72000] | Train [14400/28709] in 57.114210s
Loss: 0.694948 | Acc: 54.54% [ 58905.60/108000] | Train [21600/28709] in 57.113137s
Loss: 0.696517 | Acc: 54.34% [ 77996.93/143545] | Train [28709/28709] in 56.513881s
Val Error: Acc 67.5% | Avg loss: 1.140153 in 19.117217s
Test Error: Acc 68.0% | Avg loss: 1.130160 in 19.135148s

Epoch 50, Learning Rate [0.025771894466447835]
-------------------------------
Loss: 0.687351 | Acc: 55.42% [ 19952.22/ 36000] | Train [ 7200/28709] in 57.006992s
Loss: 0.695350 | Acc: 54.44% [ 39193.38/ 72000] | Train [14400/28709] in 57.116055s
Loss: 0.698045 | Acc: 54.15% [ 58479.60/108000] | Train [21600/28709] in 57.126503s
Loss: 0.695840 | Acc: 54.32% [ 77975.96/143545] | Train [28709/28709] in 56.521618s
Val Error: Acc 68.7% | Avg loss: 1.105008 in 19.111798s
Test Error: Acc 69.8% | Avg loss: 1.088177 in 19.128566s

Epoch 51, Learning Rate [0.025606601717798213]
-------------------------------
Loss: 0.692032 | Acc: 54.80% [ 19728.58/ 36000] | Train [ 7200/28709] in 56.988187s
Loss: 0.694200 | Acc: 54.44% [ 39195.76/ 72000] | Train [14400/28709] in 57.096279s
Loss: 0.693577 | Acc: 54.62% [ 58985.61/108000] | Train [21600/28709] in 57.110890s
Loss: 0.695347 | Acc: 54.41% [ 78102.19/143545] | Train [28709/28709] in 56.516065s
Val Error: Acc 68.9% | Avg loss: 1.103401 in 19.126629s
Test Error: Acc 69.5% | Avg loss: 1.097815 in 19.125183s
current highest Acc: 68.9%

Epoch 52, Learning Rate [0.025438691948884713]
-------------------------------
Loss: 0.688432 | Acc: 55.08% [ 19829.25/ 36000] | Train [ 7200/28709] in 56.986310s
Loss: 0.691063 | Acc: 54.90% [ 39528.24/ 72000] | Train [14400/28709] in 57.085890s
Loss: 0.693038 | Acc: 54.65% [ 59019.56/108000] | Train [21600/28709] in 57.092795s
Loss: 0.690783 | Acc: 54.88% [ 78772.51/143545] | Train [28709/28709] in 56.495379s
Val Error: Acc 68.2% | Avg loss: 1.101965 in 19.117852s
Test Error: Acc 68.5% | Avg loss: 1.084113 in 19.114945s

Epoch 53, Learning Rate [0.025268206588930333]
-------------------------------
Loss: 0.690774 | Acc: 55.06% [ 19821.17/ 36000] | Train [ 7200/28709] in 56.982738s
Loss: 0.689541 | Acc: 55.36% [ 39860.61/ 72000] | Train [14400/28709] in 57.092266s
Loss: 0.692430 | Acc: 54.96% [ 59352.57/108000] | Train [21600/28709] in 57.095531s
Loss: 0.693704 | Acc: 54.73% [ 78562.89/143545] | Train [28709/28709] in 56.493793s
Val Error: Acc 68.9% | Avg loss: 1.106686 in 19.131718s
Test Error: Acc 69.6% | Avg loss: 1.096706 in 19.124079s
current highest Acc: 68.9%

Epoch 54, Learning Rate [0.025095187702646602]
-------------------------------
Loss: 0.689299 | Acc: 54.87% [ 19752.26/ 36000] | Train [ 7200/28709] in 56.980621s
Loss: 0.691344 | Acc: 54.80% [ 39453.75/ 72000] | Train [14400/28709] in 57.077606s
Loss: 0.691771 | Acc: 54.87% [ 59256.47/108000] | Train [21600/28709] in 57.088805s
Loss: 0.691095 | Acc: 54.93% [ 78850.46/143545] | Train [28709/28709] in 56.497784s
Val Error: Acc 69.0% | Avg loss: 1.088734 in 19.117708s
Test Error: Acc 69.6% | Avg loss: 1.077868 in 19.116423s
current highest Acc: 69.0%

Epoch 55, Learning Rate [0.02491967797985478]
-------------------------------
Loss: 0.687954 | Acc: 55.36% [ 19928.08/ 36000] | Train [ 7200/28709] in 56.973096s
Loss: 0.685881 | Acc: 55.56% [ 40003.59/ 72000] | Train [14400/28709] in 57.085111s
Loss: 0.687535 | Acc: 55.30% [ 59720.24/108000] | Train [21600/28709] in 57.095271s
Loss: 0.688123 | Acc: 55.24% [ 79292.29/143545] | Train [28709/28709] in 56.514203s
Val Error: Acc 68.5% | Avg loss: 1.090438 in 19.166222s
Test Error: Acc 70.4% | Avg loss: 1.072542 in 19.118656s

Epoch 56, Learning Rate [0.024741720724952756]
-------------------------------
Loss: 0.684109 | Acc: 55.79% [ 20083.88/ 36000] | Train [ 7200/28709] in 56.990315s
Loss: 0.687240 | Acc: 55.32% [ 39830.75/ 72000] | Train [14400/28709] in 57.098443s
Loss: 0.690077 | Acc: 55.00% [ 59402.33/108000] | Train [21600/28709] in 57.080127s
Loss: 0.690331 | Acc: 54.99% [ 78939.67/143545] | Train [28709/28709] in 56.487359s
Val Error: Acc 70.3% | Avg loss: 1.098371 in 19.126221s
Test Error: Acc 70.6% | Avg loss: 1.088620 in 19.107265s
current highest Acc: 70.3%

Epoch 57, Learning Rate [0.024561359846230348]
-------------------------------
Loss: 0.691427 | Acc: 54.93% [ 19776.49/ 36000] | Train [ 7200/28709] in 56.971252s
Loss: 0.688261 | Acc: 55.29% [ 39807.92/ 72000] | Train [14400/28709] in 57.084838s
Loss: 0.686637 | Acc: 55.47% [ 59902.79/108000] | Train [21600/28709] in 57.083921s
Loss: 0.689434 | Acc: 55.11% [ 79113.24/143545] | Train [28709/28709] in 56.489960s
Val Error: Acc 69.5% | Avg loss: 1.087984 in 19.121567s
Test Error: Acc 70.3% | Avg loss: 1.077902 in 19.117723s

Epoch 58, Learning Rate [0.02437863984503558]
-------------------------------
Loss: 0.684461 | Acc: 55.72% [ 20060.08/ 36000] | Train [ 7200/28709] in 56.978474s
Loss: 0.686958 | Acc: 55.43% [ 39912.22/ 72000] | Train [14400/28709] in 57.079967s
Loss: 0.688250 | Acc: 55.28% [ 59701.82/108000] | Train [21600/28709] in 57.092442s
Loss: 0.688163 | Acc: 55.23% [ 79272.76/143545] | Train [28709/28709] in 56.491919s
Val Error: Acc 70.0% | Avg loss: 1.089252 in 19.125643s
Test Error: Acc 70.4% | Avg loss: 1.081200 in 19.116864s

Epoch 59, Learning Rate [0.02419360580479465]
-------------------------------
Loss: 0.679695 | Acc: 56.65% [ 20393.42/ 36000] | Train [ 7200/28709] in 56.977938s
Loss: 0.674886 | Acc: 56.95% [ 41004.04/ 72000] | Train [14400/28709] in 57.083252s
Loss: 0.681145 | Acc: 56.22% [ 60719.21/108000] | Train [21600/28709] in 57.078118s
Loss: 0.682050 | Acc: 56.04% [ 80440.50/143545] | Train [28709/28709] in 56.483732s
Val Error: Acc 69.4% | Avg loss: 1.098022 in 19.124096s
Test Error: Acc 70.6% | Avg loss: 1.086394 in 19.113410s

Epoch 60, Learning Rate [0.024006303379888263]
-------------------------------
Loss: 0.678515 | Acc: 56.72% [ 20418.40/ 36000] | Train [ 7200/28709] in 56.975297s
Loss: 0.677986 | Acc: 56.53% [ 40703.26/ 72000] | Train [14400/28709] in 57.078209s
Loss: 0.683019 | Acc: 55.84% [ 60306.90/108000] | Train [21600/28709] in 57.083730s
Loss: 0.685044 | Acc: 55.67% [ 79904.96/143545] | Train [28709/28709] in 56.491411s
Val Error: Acc 69.8% | Avg loss: 1.080460 in 19.125416s
Test Error: Acc 70.0% | Avg loss: 1.070805 in 19.090861s

Epoch 61, Learning Rate [0.0238167787843871]
-------------------------------
Loss: 0.671588 | Acc: 57.20% [ 20592.33/ 36000] | Train [ 7200/28709] in 56.974472s
Loss: 0.681155 | Acc: 56.18% [ 40448.45/ 72000] | Train [14400/28709] in 57.089164s
Loss: 0.681959 | Acc: 56.13% [ 60624.18/108000] | Train [21600/28709] in 57.088729s
Loss: 0.681120 | Acc: 56.20% [ 80671.29/143545] | Train [28709/28709] in 56.482507s
Val Error: Acc 70.0% | Avg loss: 1.094623 in 19.123070s
Test Error: Acc 69.9% | Avg loss: 1.081019 in 19.105157s

Epoch 62, Learning Rate [0.02362507878064918]
-------------------------------
Loss: 0.678231 | Acc: 56.22% [ 20240.60/ 36000] | Train [ 7200/28709] in 56.972650s
Loss: 0.682597 | Acc: 55.85% [ 40209.20/ 72000] | Train [14400/28709] in 57.081958s
Loss: 0.679516 | Acc: 56.17% [ 60663.71/108000] | Train [21600/28709] in 57.084234s
Loss: 0.682376 | Acc: 55.89% [ 80229.85/143545] | Train [28709/28709] in 56.495851s
Val Error: Acc 69.3% | Avg loss: 1.094599 in 19.133433s
Test Error: Acc 69.9% | Avg loss: 1.071743 in 19.105709s

Epoch 63, Learning Rate [0.023431250667781966]
-------------------------------
Loss: 0.681588 | Acc: 56.05% [ 20177.69/ 36000] | Train [ 7200/28709] in 56.980390s
Loss: 0.682634 | Acc: 55.96% [ 40294.59/ 72000] | Train [14400/28709] in 57.085556s
Loss: 0.678790 | Acc: 56.47% [ 60991.35/108000] | Train [21600/28709] in 57.090155s
Loss: 0.680137 | Acc: 56.38% [ 80925.06/143545] | Train [28709/28709] in 56.492895s
Val Error: Acc 67.9% | Avg loss: 1.103608 in 19.127173s
Test Error: Acc 69.5% | Avg loss: 1.082198 in 19.102020s

Epoch 64, Learning Rate [0.02323534226997198]
-------------------------------
Loss: 0.685548 | Acc: 55.81% [ 20089.85/ 36000] | Train [ 7200/28709] in 56.974284s
Loss: 0.679901 | Acc: 56.41% [ 40612.09/ 72000] | Train [14400/28709] in 57.087092s
Loss: 0.681815 | Acc: 56.18% [ 60671.92/108000] | Train [21600/28709] in 57.092542s
Loss: 0.681825 | Acc: 56.15% [ 80598.53/143545] | Train [28709/28709] in 56.486938s
Val Error: Acc 69.9% | Avg loss: 1.086951 in 19.130898s
Test Error: Acc 70.4% | Avg loss: 1.077829 in 19.104406s

Epoch 65, Learning Rate [0.023037401924684953]
-------------------------------
Loss: 0.671849 | Acc: 57.34% [ 20641.53/ 36000] | Train [ 7200/28709] in 56.977950s
Loss: 0.676324 | Acc: 56.87% [ 40944.39/ 72000] | Train [14400/28709] in 57.093442s
Loss: 0.677381 | Acc: 56.71% [ 61245.95/108000] | Train [21600/28709] in 57.111474s
Loss: 0.679061 | Acc: 56.52% [ 81133.16/143545] | Train [28709/28709] in 56.495399s
Val Error: Acc 70.5% | Avg loss: 1.080072 in 19.136628s
Test Error: Acc 71.5% | Avg loss: 1.064958 in 19.117206s
current highest Acc: 70.5%

Epoch 66, Learning Rate [0.022837478470739237]
-------------------------------
Loss: 0.673208 | Acc: 56.99% [ 20515.02/ 36000] | Train [ 7200/28709] in 56.971912s
Loss: 0.679833 | Acc: 56.36% [ 40578.82/ 72000] | Train [14400/28709] in 57.075707s
Loss: 0.676036 | Acc: 56.83% [ 61381.01/108000] | Train [21600/28709] in 57.094245s
Loss: 0.675832 | Acc: 56.87% [ 81630.09/143545] | Train [28709/28709] in 56.488453s
Val Error: Acc 70.4% | Avg loss: 1.075392 in 19.136290s
Test Error: Acc 69.9% | Avg loss: 1.068525 in 19.108680s

Epoch 67, Learning Rate [0.022635621236255576]
-------------------------------
Loss: 0.677445 | Acc: 56.43% [ 20316.37/ 36000] | Train [ 7200/28709] in 56.974080s
Loss: 0.675309 | Acc: 56.74% [ 40852.43/ 72000] | Train [14400/28709] in 57.079572s
Loss: 0.674372 | Acc: 56.90% [ 61448.05/108000] | Train [21600/28709] in 57.086405s
Loss: 0.675030 | Acc: 56.79% [ 81523.13/143545] | Train [28709/28709] in 56.491797s
Val Error: Acc 69.0% | Avg loss: 1.088097 in 19.131198s
Test Error: Acc 70.0% | Avg loss: 1.077091 in 19.129434s

Epoch 68, Learning Rate [0.02243188002648612]
-------------------------------
Loss: 0.674692 | Acc: 57.29% [ 20624.84/ 36000] | Train [ 7200/28709] in 56.972665s
Loss: 0.672582 | Acc: 57.39% [ 41320.77/ 72000] | Train [14400/28709] in 57.088972s
Loss: 0.675594 | Acc: 56.96% [ 61518.95/108000] | Train [21600/28709] in 57.090417s
Loss: 0.673043 | Acc: 57.19% [ 82089.48/143545] | Train [28709/28709] in 56.482176s
Val Error: Acc 69.7% | Avg loss: 1.083407 in 19.123371s
Test Error: Acc 69.7% | Avg loss: 1.074630 in 19.115662s

Epoch 69, Learning Rate [0.02222630511152573]
-------------------------------
Loss: 0.680760 | Acc: 56.24% [ 20245.43/ 36000] | Train [ 7200/28709] in 56.969890s
Loss: 0.678210 | Acc: 56.44% [ 40637.74/ 72000] | Train [14400/28709] in 57.082049s
Loss: 0.676745 | Acc: 56.60% [ 61132.82/108000] | Train [21600/28709] in 57.092129s
Loss: 0.676558 | Acc: 56.68% [ 81366.61/143545] | Train [28709/28709] in 56.483586s
Val Error: Acc 69.9% | Avg loss: 1.066840 in 19.135881s
Test Error: Acc 70.9% | Avg loss: 1.046024 in 19.110944s

Epoch 70, Learning Rate [0.022018947213908607]
-------------------------------
Loss: 0.664471 | Acc: 58.26% [ 20974.45/ 36000] | Train [ 7200/28709] in 56.977171s
Loss: 0.668091 | Acc: 57.78% [ 41604.44/ 72000] | Train [14400/28709] in 57.077812s
Loss: 0.669215 | Acc: 57.62% [ 62227.39/108000] | Train [21600/28709] in 57.083338s
Loss: 0.672888 | Acc: 57.22% [ 82140.00/143545] | Train [28709/28709] in 56.488959s
Val Error: Acc 70.5% | Avg loss: 1.088460 in 19.135636s
Test Error: Acc 70.7% | Avg loss: 1.077827 in 19.120127s
current highest Acc: 70.5%

Epoch 71, Learning Rate [0.021809857496093207]
-------------------------------
Loss: 0.663888 | Acc: 58.41% [ 21028.73/ 36000] | Train [ 7200/28709] in 56.988323s
Loss: 0.666263 | Acc: 57.93% [ 41712.27/ 72000] | Train [14400/28709] in 57.080743s
Loss: 0.668305 | Acc: 57.63% [ 62240.91/108000] | Train [21600/28709] in 57.088336s
Loss: 0.670864 | Acc: 57.37% [ 82354.36/143545] | Train [28709/28709] in 56.482502s
Val Error: Acc 69.9% | Avg loss: 1.073407 in 19.116198s
Test Error: Acc 70.7% | Avg loss: 1.055355 in 19.124255s

Epoch 72, Learning Rate [0.02159908754783873]
-------------------------------
Loss: 0.675941 | Acc: 56.77% [ 20436.83/ 36000] | Train [ 7200/28709] in 56.967288s
Loss: 0.674166 | Acc: 56.97% [ 41019.78/ 72000] | Train [14400/28709] in 57.084809s
Loss: 0.669927 | Acc: 57.47% [ 62065.15/108000] | Train [21600/28709] in 57.072993s
Loss: 0.669008 | Acc: 57.56% [ 82620.58/143545] | Train [28709/28709] in 56.476067s
Val Error: Acc 69.9% | Avg loss: 1.079394 in 19.113548s
Test Error: Acc 70.2% | Avg loss: 1.064844 in 19.110148s

Epoch 73, Learning Rate [0.021386689373476094]
-------------------------------
Loss: 0.674136 | Acc: 56.87% [ 20473.56/ 36000] | Train [ 7200/28709] in 56.961468s
Loss: 0.669346 | Acc: 57.44% [ 41357.70/ 72000] | Train [14400/28709] in 57.071513s
Loss: 0.668195 | Acc: 57.61% [ 62215.49/108000] | Train [21600/28709] in 57.069050s
Loss: 0.669397 | Acc: 57.51% [ 82559.63/143545] | Train [28709/28709] in 56.486893s
Val Error: Acc 70.5% | Avg loss: 1.072356 in 19.123680s
Test Error: Acc 71.1% | Avg loss: 1.054515 in 19.122034s

Epoch 74, Learning Rate [0.021172715379076636]
-------------------------------
Loss: 0.667835 | Acc: 57.89% [ 20840.21/ 36000] | Train [ 7200/28709] in 56.962737s
Loss: 0.670045 | Acc: 57.77% [ 41596.93/ 72000] | Train [14400/28709] in 57.066687s
Loss: 0.671233 | Acc: 57.55% [ 62158.43/108000] | Train [21600/28709] in 57.072942s
Loss: 0.670820 | Acc: 57.50% [ 82535.30/143545] | Train [28709/28709] in 56.467224s
Val Error: Acc 70.3% | Avg loss: 1.083571 in 19.120621s
Test Error: Acc 71.1% | Avg loss: 1.073096 in 19.116101s

Epoch 75, Learning Rate [0.02095721835952171]
-------------------------------
Loss: 0.661832 | Acc: 58.34% [ 21004.10/ 36000] | Train [ 7200/28709] in 56.959192s
Loss: 0.663666 | Acc: 58.11% [ 41841.87/ 72000] | Train [14400/28709] in 57.068956s
Loss: 0.665364 | Acc: 57.94% [ 62570.25/108000] | Train [21600/28709] in 57.071239s
Loss: 0.668439 | Acc: 57.61% [ 82701.52/143545] | Train [28709/28709] in 56.471122s
Val Error: Acc 69.4% | Avg loss: 1.085837 in 19.108652s
Test Error: Acc 69.5% | Avg loss: 1.074042 in 19.123131s

Epoch 76, Learning Rate [0.02074025148547635]
-------------------------------
Loss: 0.670261 | Acc: 57.58% [ 20728.42/ 36000] | Train [ 7200/28709] in 56.962926s
Loss: 0.667971 | Acc: 57.83% [ 41634.89/ 72000] | Train [14400/28709] in 57.071945s
Loss: 0.667395 | Acc: 57.93% [ 62568.13/108000] | Train [21600/28709] in 57.073422s
Loss: 0.667905 | Acc: 57.91% [ 83122.52/143545] | Train [28709/28709] in 56.480441s
Val Error: Acc 69.5% | Avg loss: 1.087494 in 19.119159s
Test Error: Acc 70.4% | Avg loss: 1.073760 in 19.125642s

Epoch 77, Learning Rate [0.020521868290270175]
-------------------------------
Loss: 0.657627 | Acc: 59.03% [ 21251.62/ 36000] | Train [ 7200/28709] in 56.961881s
Loss: 0.661770 | Acc: 58.44% [ 42076.63/ 72000] | Train [14400/28709] in 57.066504s
Loss: 0.661664 | Acc: 58.49% [ 63170.25/108000] | Train [21600/28709] in 57.068069s
Loss: 0.663880 | Acc: 58.23% [ 83585.63/143545] | Train [28709/28709] in 56.476751s
Val Error: Acc 70.9% | Avg loss: 1.076142 in 19.079655s
Test Error: Acc 71.7% | Avg loss: 1.061712 in 19.126173s
current highest Acc: 70.9%

Epoch 78, Learning Rate [0.02030212265668886]
-------------------------------
Loss: 0.669341 | Acc: 57.67% [ 20761.26/ 36000] | Train [ 7200/28709] in 56.967012s
Loss: 0.669304 | Acc: 57.73% [ 41565.37/ 72000] | Train [14400/28709] in 57.069852s
Loss: 0.670303 | Acc: 57.65% [ 62265.67/108000] | Train [21600/28709] in 57.070649s
Loss: 0.670151 | Acc: 57.69% [ 82804.71/143545] | Train [28709/28709] in 56.474706s
Val Error: Acc 69.7% | Avg loss: 1.081778 in 19.099558s
Test Error: Acc 70.9% | Avg loss: 1.056846 in 19.130718s

Epoch 79, Learning Rate [0.020081068803679374]
-------------------------------
Loss: 0.665010 | Acc: 58.30% [ 20987.32/ 36000] | Train [ 7200/28709] in 56.955245s
Loss: 0.664725 | Acc: 58.29% [ 41968.56/ 72000] | Train [14400/28709] in 57.059365s
Loss: 0.663929 | Acc: 58.45% [ 63120.75/108000] | Train [21600/28709] in 57.069362s
Loss: 0.664059 | Acc: 58.42% [ 83853.35/143545] | Train [28709/28709] in 56.467995s
Val Error: Acc 71.0% | Avg loss: 1.063165 in 19.107977s
Test Error: Acc 70.7% | Avg loss: 1.044650 in 19.127904s
current highest Acc: 71.0%

Epoch 80, Learning Rate [0.01985876127297224]
-------------------------------
Loss: 0.661490 | Acc: 58.58% [ 21088.46/ 36000] | Train [ 7200/28709] in 56.968672s
Loss: 0.661161 | Acc: 58.58% [ 42180.57/ 72000] | Train [14400/28709] in 57.071613s
Loss: 0.659892 | Acc: 58.73% [ 63424.07/108000] | Train [21600/28709] in 57.075872s
Loss: 0.659891 | Acc: 58.72% [ 84285.56/143545] | Train [28709/28709] in 56.473786s
Val Error: Acc 70.5% | Avg loss: 1.074499 in 19.114889s
Test Error: Acc 71.1% | Avg loss: 1.060520 in 19.131651s

Epoch 81, Learning Rate [0.01963525491562421]
-------------------------------
Loss: 0.659485 | Acc: 58.53% [ 21072.24/ 36000] | Train [ 7200/28709] in 56.953695s
Loss: 0.661286 | Acc: 58.54% [ 42146.74/ 72000] | Train [14400/28709] in 57.065385s
Loss: 0.660699 | Acc: 58.62% [ 63307.03/108000] | Train [21600/28709] in 57.066254s
Loss: 0.662285 | Acc: 58.42% [ 83858.37/143545] | Train [28709/28709] in 56.470132s
Val Error: Acc 70.5% | Avg loss: 1.070161 in 19.120574s
Test Error: Acc 71.3% | Avg loss: 1.054364 in 19.126648s

Epoch 82, Learning Rate [0.019410604878484557]
-------------------------------
Loss: 0.659628 | Acc: 58.63% [ 21105.61/ 36000] | Train [ 7200/28709] in 56.962803s
Loss: 0.660858 | Acc: 58.58% [ 42175.05/ 72000] | Train [14400/28709] in 57.077474s
Loss: 0.664075 | Acc: 58.23% [ 62890.82/108000] | Train [21600/28709] in 57.082718s
Loss: 0.664757 | Acc: 58.14% [ 83458.50/143545] | Train [28709/28709] in 56.477795s
Val Error: Acc 70.6% | Avg loss: 1.071761 in 19.112489s
Test Error: Acc 71.4% | Avg loss: 1.056603 in 19.153712s

Epoch 83, Learning Rate [0.019184866590588438]
-------------------------------
Loss: 0.660425 | Acc: 58.90% [ 21205.67/ 36000] | Train [ 7200/28709] in 56.977257s
Loss: 0.659237 | Acc: 58.79% [ 42325.74/ 72000] | Train [14400/28709] in 57.073376s
Loss: 0.661096 | Acc: 58.63% [ 63318.74/108000] | Train [21600/28709] in 57.075483s
Loss: 0.661521 | Acc: 58.56% [ 84060.21/143545] | Train [28709/28709] in 56.468375s
Val Error: Acc 70.8% | Avg loss: 1.077011 in 19.111471s
Test Error: Acc 72.0% | Avg loss: 1.052443 in 19.135150s

Epoch 84, Learning Rate [0.018958095749480586]
-------------------------------
Loss: 0.661374 | Acc: 58.66% [ 21118.77/ 36000] | Train [ 7200/28709] in 56.967520s
Loss: 0.662575 | Acc: 58.62% [ 42209.18/ 72000] | Train [14400/28709] in 57.072299s
Loss: 0.659614 | Acc: 58.84% [ 63547.40/108000] | Train [21600/28709] in 57.068480s
Loss: 0.660073 | Acc: 58.79% [ 84395.60/143545] | Train [28709/28709] in 56.474737s
Val Error: Acc 69.9% | Avg loss: 1.073021 in 19.113457s
Test Error: Acc 70.4% | Avg loss: 1.059625 in 19.122960s

Epoch 85, Learning Rate [0.018730348307472815]
-------------------------------
Loss: 0.657919 | Acc: 58.84% [ 21183.55/ 36000] | Train [ 7200/28709] in 56.960512s
Loss: 0.660598 | Acc: 58.58% [ 42179.20/ 72000] | Train [14400/28709] in 57.067884s
Loss: 0.662148 | Acc: 58.48% [ 63163.54/108000] | Train [21600/28709] in 57.064664s
Loss: 0.661741 | Acc: 58.56% [ 84064.22/143545] | Train [28709/28709] in 56.473841s
Val Error: Acc 70.5% | Avg loss: 1.079371 in 19.113502s
Test Error: Acc 72.4% | Avg loss: 1.058283 in 19.123989s

Epoch 86, Learning Rate [0.01850168045783858]
-------------------------------
Loss: 0.642140 | Acc: 61.08% [ 21990.05/ 36000] | Train [ 7200/28709] in 56.958433s
Loss: 0.649302 | Acc: 60.14% [ 43303.42/ 72000] | Train [14400/28709] in 57.068016s
Loss: 0.652847 | Acc: 59.76% [ 64536.50/108000] | Train [21600/28709] in 57.065357s
Loss: 0.654807 | Acc: 59.45% [ 85334.59/143545] | Train [28709/28709] in 56.460960s
Val Error: Acc 70.7% | Avg loss: 1.064207 in 19.111734s
Test Error: Acc 72.2% | Avg loss: 1.042585 in 19.097999s

Epoch 87, Learning Rate [0.01827214862094814]
-------------------------------
Loss: 0.649369 | Acc: 59.86% [ 21550.63/ 36000] | Train [ 7200/28709] in 56.957333s
Loss: 0.646982 | Acc: 60.15% [ 43311.15/ 72000] | Train [14400/28709] in 57.068725s
Loss: 0.652690 | Acc: 59.48% [ 64241.93/108000] | Train [21600/28709] in 57.070901s
Loss: 0.654485 | Acc: 59.34% [ 85176.21/143545] | Train [28709/28709] in 56.476154s
Val Error: Acc 70.4% | Avg loss: 1.075002 in 19.125864s
Test Error: Acc 71.4% | Avg loss: 1.052356 in 19.114447s

Epoch 88, Learning Rate [0.018041809430347687]
-------------------------------
Loss: 0.650634 | Acc: 59.69% [ 21488.65/ 36000] | Train [ 7200/28709] in 56.964826s
Loss: 0.653715 | Acc: 59.31% [ 42705.57/ 72000] | Train [14400/28709] in 57.058416s
Loss: 0.653678 | Acc: 59.38% [ 64134.43/108000] | Train [21600/28709] in 57.065947s
Loss: 0.655214 | Acc: 59.24% [ 85034.05/143545] | Train [28709/28709] in 56.469382s
Val Error: Acc 70.0% | Avg loss: 1.094884 in 19.122332s
Test Error: Acc 71.1% | Avg loss: 1.074114 in 19.117119s

Epoch 89, Learning Rate [0.01781071971878587]
-------------------------------
Loss: 0.648175 | Acc: 59.99% [ 21596.47/ 36000] | Train [ 7200/28709] in 56.953472s
Loss: 0.654711 | Acc: 59.23% [ 42648.45/ 72000] | Train [14400/28709] in 57.064670s
Loss: 0.657038 | Acc: 59.11% [ 63842.31/108000] | Train [21600/28709] in 57.063318s
Loss: 0.656087 | Acc: 59.16% [ 84923.35/143545] | Train [28709/28709] in 56.465031s
Val Error: Acc 70.3% | Avg loss: 1.075375 in 19.122133s
Test Error: Acc 71.5% | Avg loss: 1.052130 in 19.114144s

Epoch 90, Learning Rate [0.01757893650419114]
-------------------------------
Loss: 0.643755 | Acc: 60.54% [ 21795.45/ 36000] | Train [ 7200/28709] in 56.958457s
Loss: 0.645371 | Acc: 60.31% [ 43425.93/ 72000] | Train [14400/28709] in 57.062602s
Loss: 0.644519 | Acc: 60.53% [ 65376.45/108000] | Train [21600/28709] in 57.070275s
Loss: 0.647716 | Acc: 60.23% [ 86463.10/143545] | Train [28709/28709] in 56.458405s
Val Error: Acc 70.7% | Avg loss: 1.074784 in 19.122289s
Test Error: Acc 71.4% | Avg loss: 1.056424 in 19.109190s

Epoch 91, Learning Rate [0.017346516975603462]
-------------------------------
Loss: 0.656097 | Acc: 59.01% [ 21243.34/ 36000] | Train [ 7200/28709] in 56.943767s
Loss: 0.655047 | Acc: 59.30% [ 42699.47/ 72000] | Train [14400/28709] in 57.060013s
Loss: 0.655668 | Acc: 59.27% [ 64009.72/108000] | Train [21600/28709] in 57.061439s
Loss: 0.656338 | Acc: 59.17% [ 84935.01/143545] | Train [28709/28709] in 56.448004s
Val Error: Acc 70.2% | Avg loss: 1.086038 in 19.107585s
Test Error: Acc 71.4% | Avg loss: 1.063389 in 19.104958s

Epoch 92, Learning Rate [0.01711351847906374]
-------------------------------
Loss: 0.640799 | Acc: 61.00% [ 21961.16/ 36000] | Train [ 7200/28709] in 56.944478s
Loss: 0.647436 | Acc: 60.31% [ 43424.69/ 72000] | Train [14400/28709] in 57.056461s
Loss: 0.646941 | Acc: 60.37% [ 65201.48/108000] | Train [21600/28709] in 57.064960s
Loss: 0.646287 | Acc: 60.44% [ 86757.52/143545] | Train [28709/28709] in 56.459548s
Val Error: Acc 71.2% | Avg loss: 1.075064 in 19.111916s
Test Error: Acc 71.5% | Avg loss: 1.053575 in 19.093047s
current highest Acc: 71.2%

Epoch 93, Learning Rate [0.016879998503464565]
-------------------------------
Loss: 0.647456 | Acc: 60.12% [ 21643.40/ 36000] | Train [ 7200/28709] in 56.942667s
Loss: 0.647652 | Acc: 60.19% [ 43335.37/ 72000] | Train [14400/28709] in 57.050344s
Loss: 0.648555 | Acc: 60.10% [ 64903.90/108000] | Train [21600/28709] in 57.055923s
Loss: 0.649069 | Acc: 60.01% [ 86144.88/143545] | Train [28709/28709] in 56.457786s
Val Error: Acc 71.5% | Avg loss: 1.055004 in 19.115276s
Test Error: Acc 72.4% | Avg loss: 1.035740 in 19.083719s
current highest Acc: 71.5%

Epoch 94, Learning Rate [0.01664601466636568]
-------------------------------
Loss: 0.652235 | Acc: 59.78% [ 21520.76/ 36000] | Train [ 7200/28709] in 56.942525s
Loss: 0.650515 | Acc: 60.01% [ 43206.90/ 72000] | Train [14400/28709] in 57.054437s
Loss: 0.647623 | Acc: 60.32% [ 65148.42/108000] | Train [21600/28709] in 57.055999s
Loss: 0.647358 | Acc: 60.25% [ 86485.96/143545] | Train [28709/28709] in 56.453266s
Val Error: Acc 70.8% | Avg loss: 1.082459 in 19.096637s
Test Error: Acc 71.7% | Avg loss: 1.076555 in 19.093795s

Epoch 95, Learning Rate [0.016411624699777715]
-------------------------------
Loss: 0.653360 | Acc: 59.68% [ 21485.46/ 36000] | Train [ 7200/28709] in 56.946496s
Loss: 0.651767 | Acc: 59.83% [ 43077.05/ 72000] | Train [14400/28709] in 57.056254s
Loss: 0.651239 | Acc: 59.86% [ 64644.88/108000] | Train [21600/28709] in 57.060643s
Loss: 0.648979 | Acc: 60.14% [ 86332.42/143545] | Train [28709/28709] in 56.459692s
Val Error: Acc 71.2% | Avg loss: 1.065277 in 19.108161s
Test Error: Acc 72.4% | Avg loss: 1.046645 in 19.099629s

Epoch 96, Learning Rate [0.016176886435917675]
-------------------------------
Loss: 0.645806 | Acc: 60.44% [ 21756.93/ 36000] | Train [ 7200/28709] in 56.955927s
Loss: 0.643993 | Acc: 60.65% [ 43664.53/ 72000] | Train [14400/28709] in 57.047716s
Loss: 0.645298 | Acc: 60.52% [ 65363.24/108000] | Train [21600/28709] in 57.070169s
Loss: 0.646491 | Acc: 60.35% [ 86624.63/143545] | Train [28709/28709] in 56.465908s
Val Error: Acc 71.1% | Avg loss: 1.076458 in 19.103160s
Test Error: Acc 72.0% | Avg loss: 1.058425 in 19.091172s

Epoch 97, Learning Rate [0.0159418577929397]
-------------------------------
Loss: 0.636839 | Acc: 61.69% [ 22207.77/ 36000] | Train [ 7200/28709] in 56.958317s
Loss: 0.635508 | Acc: 61.83% [ 44514.41/ 72000] | Train [14400/28709] in 57.063499s
Loss: 0.638448 | Acc: 61.49% [ 66406.34/108000] | Train [21600/28709] in 57.061746s
Loss: 0.638762 | Acc: 61.40% [ 88141.57/143545] | Train [28709/28709] in 56.461168s
Val Error: Acc 71.5% | Avg loss: 1.055131 in 19.102162s
Test Error: Acc 72.2% | Avg loss: 1.043555 in 19.100588s

Epoch 98, Learning Rate [0.015706596760644637]
-------------------------------
Loss: 0.643891 | Acc: 60.84% [ 21902.43/ 36000] | Train [ 7200/28709] in 56.953618s
Loss: 0.641795 | Acc: 60.95% [ 43885.48/ 72000] | Train [14400/28709] in 57.072250s
Loss: 0.644761 | Acc: 60.63% [ 65484.07/108000] | Train [21600/28709] in 57.062422s
Loss: 0.645300 | Acc: 60.50% [ 86846.67/143545] | Train [28709/28709] in 56.462444s
Val Error: Acc 71.1% | Avg loss: 1.063987 in 19.105179s
Test Error: Acc 72.2% | Avg loss: 1.046407 in 19.100718s

Epoch 99, Learning Rate [0.015471161386171923]
-------------------------------
Loss: 0.645818 | Acc: 60.51% [ 21783.74/ 36000] | Train [ 7200/28709] in 56.950730s
Loss: 0.640248 | Acc: 61.07% [ 43972.33/ 72000] | Train [14400/28709] in 57.063246s
Loss: 0.638778 | Acc: 61.22% [ 66112.32/108000] | Train [21600/28709] in 57.050206s
Loss: 0.642841 | Acc: 60.75% [ 87201.73/143545] | Train [28709/28709] in 56.459889s
Val Error: Acc 70.8% | Avg loss: 1.071785 in 19.102171s
Test Error: Acc 72.2% | Avg loss: 1.057489 in 19.107925s

Epoch 100, Learning Rate [0.01523560975967731]
-------------------------------
Loss: 0.639082 | Acc: 61.30% [ 22066.70/ 36000] | Train [ 7200/28709] in 56.951547s
Loss: 0.637636 | Acc: 61.55% [ 44316.24/ 72000] | Train [14400/28709] in 57.058219s
Loss: 0.637785 | Acc: 61.49% [ 66410.30/108000] | Train [21600/28709] in 57.060667s
Loss: 0.638887 | Acc: 61.36% [ 88084.83/143545] | Train [28709/28709] in 56.466978s
Val Error: Acc 71.7% | Avg loss: 1.055888 in 19.113945s
Test Error: Acc 73.0% | Avg loss: 1.042908 in 19.102872s
current highest Acc: 71.7%

Epoch 101, Learning Rate [0.014999999999999998]
-------------------------------
Loss: 0.635498 | Acc: 61.93% [ 22293.54/ 36000] | Train [ 7200/28709] in 56.958400s
Loss: 0.641379 | Acc: 61.17% [ 44043.02/ 72000] | Train [14400/28709] in 57.066904s
Loss: 0.641759 | Acc: 61.10% [ 65983.38/108000] | Train [21600/28709] in 57.063556s
Loss: 0.640464 | Acc: 61.21% [ 87865.94/143545] | Train [28709/28709] in 56.474853s
Val Error: Acc 71.5% | Avg loss: 1.071479 in 19.101949s
Test Error: Acc 72.3% | Avg loss: 1.049416 in 19.112738s

Epoch 102, Learning Rate [0.01476439024032269]
-------------------------------
Loss: 0.635322 | Acc: 61.68% [ 22204.78/ 36000] | Train [ 7200/28709] in 56.951073s
Loss: 0.636765 | Acc: 61.35% [ 44173.27/ 72000] | Train [14400/28709] in 57.064255s
Loss: 0.636990 | Acc: 61.34% [ 66249.44/108000] | Train [21600/28709] in 57.063030s
Loss: 0.639443 | Acc: 61.10% [ 87703.71/143545] | Train [28709/28709] in 56.464793s
Val Error: Acc 71.5% | Avg loss: 1.067479 in 19.106267s
Test Error: Acc 73.2% | Avg loss: 1.052121 in 19.110857s

Epoch 103, Learning Rate [0.014528838613828072]
-------------------------------
Loss: 0.641766 | Acc: 61.13% [ 22005.29/ 36000] | Train [ 7200/28709] in 56.954836s
Loss: 0.634925 | Acc: 61.99% [ 44630.77/ 72000] | Train [14400/28709] in 57.061656s
Loss: 0.634581 | Acc: 61.92% [ 66875.33/108000] | Train [21600/28709] in 57.062505s
Loss: 0.636885 | Acc: 61.64% [ 88476.93/143545] | Train [28709/28709] in 56.460867s
Val Error: Acc 71.4% | Avg loss: 1.061948 in 19.107073s
Test Error: Acc 72.8% | Avg loss: 1.050888 in 19.083431s

Epoch 104, Learning Rate [0.014293403239355358]
-------------------------------
Loss: 0.626411 | Acc: 62.48% [ 22493.06/ 36000] | Train [ 7200/28709] in 56.949893s
Loss: 0.632893 | Acc: 61.97% [ 44616.74/ 72000] | Train [14400/28709] in 57.061737s
Loss: 0.639518 | Acc: 61.26% [ 66157.53/108000] | Train [21600/28709] in 57.056961s
Loss: 0.640820 | Acc: 61.11% [ 87717.74/143545] | Train [28709/28709] in 56.468943s
Val Error: Acc 71.1% | Avg loss: 1.071929 in 19.104151s
Test Error: Acc 72.4% | Avg loss: 1.055313 in 19.106191s

Epoch 105, Learning Rate [0.014058142207060297]
-------------------------------
Loss: 0.634695 | Acc: 61.87% [ 22274.03/ 36000] | Train [ 7200/28709] in 56.946614s
Loss: 0.637376 | Acc: 61.60% [ 44351.86/ 72000] | Train [14400/28709] in 57.065868s
Loss: 0.636341 | Acc: 61.77% [ 66708.98/108000] | Train [21600/28709] in 57.057999s
Loss: 0.637791 | Acc: 61.55% [ 88349.75/143545] | Train [28709/28709] in 56.464601s
Val Error: Acc 71.9% | Avg loss: 1.070737 in 19.103238s
Test Error: Acc 72.6% | Avg loss: 1.050462 in 19.109020s
current highest Acc: 71.9%

Epoch 106, Learning Rate [0.013823113564082326]
-------------------------------
Loss: 0.633006 | Acc: 62.11% [ 22359.63/ 36000] | Train [ 7200/28709] in 56.956450s
Loss: 0.631494 | Acc: 62.16% [ 44753.88/ 72000] | Train [14400/28709] in 57.057933s
Loss: 0.628796 | Acc: 62.36% [ 67352.94/108000] | Train [21600/28709] in 57.056630s
Loss: 0.632698 | Acc: 61.98% [ 88969.28/143545] | Train [28709/28709] in 56.456227s
Val Error: Acc 71.4% | Avg loss: 1.053958 in 19.118445s
Test Error: Acc 72.9% | Avg loss: 1.040613 in 19.103361s

Epoch 107, Learning Rate [0.013588375300222283]
-------------------------------
Loss: 0.622751 | Acc: 63.13% [ 22727.66/ 36000] | Train [ 7200/28709] in 56.951109s
Loss: 0.627765 | Acc: 62.66% [ 45115.86/ 72000] | Train [14400/28709] in 57.062255s
Loss: 0.628098 | Acc: 62.53% [ 67534.88/108000] | Train [21600/28709] in 57.056272s
Loss: 0.629294 | Acc: 62.42% [ 89597.99/143545] | Train [28709/28709] in 56.459618s
Val Error: Acc 71.5% | Avg loss: 1.066035 in 19.102033s
Test Error: Acc 73.1% | Avg loss: 1.043773 in 19.111042s

Epoch 108, Learning Rate [0.013353985333634319]
-------------------------------
Loss: 0.624438 | Acc: 63.02% [ 22687.91/ 36000] | Train [ 7200/28709] in 56.938617s
Loss: 0.628607 | Acc: 62.49% [ 44990.87/ 72000] | Train [14400/28709] in 57.054563s
Loss: 0.628307 | Acc: 62.51% [ 67515.36/108000] | Train [21600/28709] in 57.055306s
Loss: 0.629706 | Acc: 62.37% [ 89535.44/143545] | Train [28709/28709] in 56.455912s
Val Error: Acc 70.6% | Avg loss: 1.063308 in 19.101070s
Test Error: Acc 72.8% | Avg loss: 1.034589 in 19.107695s

Epoch 109, Learning Rate [0.013120001496535435]
-------------------------------
Loss: 0.635584 | Acc: 61.76% [ 22234.97/ 36000] | Train [ 7200/28709] in 56.947976s
Loss: 0.635474 | Acc: 61.74% [ 44452.03/ 72000] | Train [14400/28709] in 57.049742s
Loss: 0.634816 | Acc: 61.78% [ 66722.80/108000] | Train [21600/28709] in 57.061742s
Loss: 0.633759 | Acc: 61.95% [ 88920.20/143545] | Train [28709/28709] in 56.455287s
Val Error: Acc 71.0% | Avg loss: 1.063477 in 19.090050s
Test Error: Acc 72.9% | Avg loss: 1.044617 in 19.100238s

Epoch 110, Learning Rate [0.012886481520936261]
-------------------------------
Loss: 0.613660 | Acc: 64.05% [ 23057.97/ 36000] | Train [ 7200/28709] in 56.981100s
Loss: 0.621217 | Acc: 63.26% [ 45546.19/ 72000] | Train [14400/28709] in 57.066248s
Loss: 0.625227 | Acc: 62.85% [ 67872.72/108000] | Train [21600/28709] in 57.058971s
Loss: 0.625514 | Acc: 62.79% [ 90137.54/143545] | Train [28709/28709] in 56.449711s
Val Error: Acc 70.7% | Avg loss: 1.076114 in 19.096051s
Test Error: Acc 73.3% | Avg loss: 1.044438 in 19.113870s

Epoch 111, Learning Rate [0.012653483024396535]
-------------------------------
Loss: 0.626030 | Acc: 62.99% [ 22675.33/ 36000] | Train [ 7200/28709] in 56.944265s
Loss: 0.626178 | Acc: 62.88% [ 45273.64/ 72000] | Train [14400/28709] in 57.044392s
Loss: 0.626817 | Acc: 62.78% [ 67797.96/108000] | Train [21600/28709] in 57.054430s
Loss: 0.626442 | Acc: 62.82% [ 90170.60/143545] | Train [28709/28709] in 56.460566s
Val Error: Acc 70.7% | Avg loss: 1.078760 in 19.078479s
Test Error: Acc 72.6% | Avg loss: 1.052822 in 19.110875s

Epoch 112, Learning Rate [0.012421063495808854]
-------------------------------
Loss: 0.618443 | Acc: 63.42% [ 22831.84/ 36000] | Train [ 7200/28709] in 56.945838s
Loss: 0.624612 | Acc: 62.85% [ 45255.04/ 72000] | Train [14400/28709] in 57.056652s
Loss: 0.625295 | Acc: 62.81% [ 67831.74/108000] | Train [21600/28709] in 57.064402s
Loss: 0.627493 | Acc: 62.56% [ 89799.99/143545] | Train [28709/28709] in 56.461399s
Val Error: Acc 71.2% | Avg loss: 1.072443 in 19.087142s
Test Error: Acc 72.6% | Avg loss: 1.054348 in 19.109367s

Epoch 113, Learning Rate [0.01218928028121413]
-------------------------------
Loss: 0.625198 | Acc: 62.72% [ 22577.49/ 36000] | Train [ 7200/28709] in 56.940264s
Loss: 0.627246 | Acc: 62.61% [ 45078.43/ 72000] | Train [14400/28709] in 57.058981s
Loss: 0.627755 | Acc: 62.57% [ 67576.07/108000] | Train [21600/28709] in 57.058130s
Loss: 0.628690 | Acc: 62.48% [ 89693.72/143545] | Train [28709/28709] in 56.460661s
Val Error: Acc 72.5% | Avg loss: 1.055887 in 19.104616s
Test Error: Acc 73.1% | Avg loss: 1.036758 in 19.119184s
current highest Acc: 72.5%

Epoch 114, Learning Rate [0.011958190569652314]
-------------------------------
Loss: 0.606753 | Acc: 64.89% [ 23359.52/ 36000] | Train [ 7200/28709] in 56.958726s
Loss: 0.616883 | Acc: 63.89% [ 45998.14/ 72000] | Train [14400/28709] in 57.073117s
Loss: 0.619255 | Acc: 63.64% [ 68728.71/108000] | Train [21600/28709] in 57.067110s
Loss: 0.622042 | Acc: 63.29% [ 90845.24/143545] | Train [28709/28709] in 56.474969s
Val Error: Acc 71.9% | Avg loss: 1.050730 in 19.123646s
Test Error: Acc 73.4% | Avg loss: 1.030721 in 19.098437s

Epoch 115, Learning Rate [0.011727851379051865]
-------------------------------
Loss: 0.609644 | Acc: 64.56% [ 23239.85/ 36000] | Train [ 7200/28709] in 56.957268s
Loss: 0.613280 | Acc: 64.20% [ 46223.29/ 72000] | Train [14400/28709] in 57.064268s
Loss: 0.616359 | Acc: 63.87% [ 68976.36/108000] | Train [21600/28709] in 57.075987s
Loss: 0.618156 | Acc: 63.64% [ 91357.41/143545] | Train [28709/28709] in 56.468547s
Val Error: Acc 71.0% | Avg loss: 1.062530 in 19.129483s
Test Error: Acc 73.7% | Avg loss: 1.024518 in 19.102130s

Epoch 116, Learning Rate [0.011498319542161416]
-------------------------------
Loss: 0.625283 | Acc: 63.02% [ 22688.08/ 36000] | Train [ 7200/28709] in 56.960106s
Loss: 0.623470 | Acc: 63.27% [ 45550.85/ 72000] | Train [14400/28709] in 57.070996s
Loss: 0.623826 | Acc: 63.14% [ 68188.58/108000] | Train [21600/28709] in 57.064477s
Loss: 0.627851 | Acc: 62.60% [ 89862.64/143545] | Train [28709/28709] in 56.469368s
Val Error: Acc 72.5% | Avg loss: 1.067545 in 19.109468s
Test Error: Acc 73.4% | Avg loss: 1.047500 in 19.087961s

Epoch 117, Learning Rate [0.011269651692527177]
-------------------------------
Loss: 0.632871 | Acc: 62.37% [ 22452.08/ 36000] | Train [ 7200/28709] in 56.960601s
Loss: 0.625119 | Acc: 63.04% [ 45391.92/ 72000] | Train [14400/28709] in 57.063332s
Loss: 0.623761 | Acc: 63.11% [ 68154.32/108000] | Train [21600/28709] in 57.070404s
Loss: 0.624854 | Acc: 62.93% [ 90339.92/143545] | Train [28709/28709] in 56.469063s
Val Error: Acc 71.6% | Avg loss: 1.057997 in 19.110262s
Test Error: Acc 72.6% | Avg loss: 1.040184 in 19.094017s

Epoch 118, Learning Rate [0.011041904250519406]
-------------------------------
Loss: 0.615842 | Acc: 63.91% [ 23008.03/ 36000] | Train [ 7200/28709] in 56.973415s
Loss: 0.619352 | Acc: 63.62% [ 45808.65/ 72000] | Train [14400/28709] in 57.079236s
Loss: 0.621946 | Acc: 63.31% [ 68372.52/108000] | Train [21600/28709] in 57.071963s
Loss: 0.621435 | Acc: 63.33% [ 90907.78/143545] | Train [28709/28709] in 56.477034s
Val Error: Acc 71.3% | Avg loss: 1.057436 in 19.121808s
Test Error: Acc 73.5% | Avg loss: 1.029728 in 19.104075s

Epoch 119, Learning Rate [0.010815133409411561]
-------------------------------
Loss: 0.616610 | Acc: 63.87% [ 22994.58/ 36000] | Train [ 7200/28709] in 56.954712s
Loss: 0.616973 | Acc: 63.92% [ 46025.35/ 72000] | Train [14400/28709] in 57.066654s
Loss: 0.614012 | Acc: 64.26% [ 69402.45/108000] | Train [21600/28709] in 57.067927s
Loss: 0.617445 | Acc: 63.83% [ 91621.19/143545] | Train [28709/28709] in 56.472404s
Val Error: Acc 72.1% | Avg loss: 1.054349 in 19.125199s
Test Error: Acc 73.8% | Avg loss: 1.028606 in 19.117100s

Epoch 120, Learning Rate [0.010589395121515442]
-------------------------------
Loss: 0.609312 | Acc: 64.55% [ 23239.49/ 36000] | Train [ 7200/28709] in 56.960949s
Loss: 0.609977 | Acc: 64.58% [ 46494.92/ 72000] | Train [14400/28709] in 57.064215s
Loss: 0.613795 | Acc: 64.08% [ 69205.73/108000] | Train [21600/28709] in 57.062732s
Loss: 0.614942 | Acc: 63.95% [ 91793.10/143545] | Train [28709/28709] in 56.466823s
Val Error: Acc 71.0% | Avg loss: 1.081798 in 19.118157s
Test Error: Acc 72.5% | Avg loss: 1.054366 in 19.107422s

Epoch 121, Learning Rate [0.010364745084375793]
-------------------------------
Loss: 0.614887 | Acc: 64.05% [ 23056.77/ 36000] | Train [ 7200/28709] in 56.954668s
Loss: 0.611383 | Acc: 64.40% [ 46369.80/ 72000] | Train [14400/28709] in 57.062656s
Loss: 0.609241 | Acc: 64.65% [ 69819.65/108000] | Train [21600/28709] in 57.059730s
Loss: 0.610155 | Acc: 64.48% [ 92564.54/143545] | Train [28709/28709] in 56.468036s
Val Error: Acc 71.3% | Avg loss: 1.056754 in 19.122497s
Test Error: Acc 73.6% | Avg loss: 1.032728 in 19.109267s

Epoch 122, Learning Rate [0.010141238727027758]
-------------------------------
Loss: 0.608119 | Acc: 65.02% [ 23405.74/ 36000] | Train [ 7200/28709] in 56.959603s
Loss: 0.615227 | Acc: 64.13% [ 46175.99/ 72000] | Train [14400/28709] in 57.062379s
Loss: 0.618288 | Acc: 63.80% [ 68904.08/108000] | Train [21600/28709] in 57.063631s
Loss: 0.618249 | Acc: 63.78% [ 91547.59/143545] | Train [28709/28709] in 56.471565s
Val Error: Acc 71.9% | Avg loss: 1.065255 in 19.108548s
Test Error: Acc 73.8% | Avg loss: 1.043932 in 19.106173s

Epoch 123, Learning Rate [0.009918931196320629]
-------------------------------
Loss: 0.623618 | Acc: 63.07% [ 22705.26/ 36000] | Train [ 7200/28709] in 56.964805s
Loss: 0.622411 | Acc: 63.41% [ 45654.89/ 72000] | Train [14400/28709] in 57.069211s
Loss: 0.618420 | Acc: 63.81% [ 68913.60/108000] | Train [21600/28709] in 57.087050s
Loss: 0.616906 | Acc: 63.95% [ 91802.10/143545] | Train [28709/28709] in 56.480664s
Val Error: Acc 71.6% | Avg loss: 1.055241 in 19.104152s
Test Error: Acc 73.4% | Avg loss: 1.030270 in 19.108171s

Epoch 124, Learning Rate [0.009697877343311144]
-------------------------------
Loss: 0.613327 | Acc: 64.33% [ 23158.51/ 36000] | Train [ 7200/28709] in 56.944421s
Loss: 0.613905 | Acc: 64.26% [ 46268.75/ 72000] | Train [14400/28709] in 57.055114s
Loss: 0.615686 | Acc: 64.10% [ 69227.80/108000] | Train [21600/28709] in 57.048185s
Loss: 0.615270 | Acc: 64.17% [ 92116.81/143545] | Train [28709/28709] in 56.458976s
Val Error: Acc 70.7% | Avg loss: 1.075631 in 19.104371s
Test Error: Acc 73.2% | Avg loss: 1.041693 in 19.100916s

Epoch 125, Learning Rate [0.009478131709729833]
-------------------------------
Loss: 0.612737 | Acc: 64.73% [ 23303.53/ 36000] | Train [ 7200/28709] in 56.961438s
Loss: 0.610654 | Acc: 64.76% [ 46628.46/ 72000] | Train [14400/28709] in 57.058371s
Loss: 0.606012 | Acc: 65.24% [ 70457.57/108000] | Train [21600/28709] in 57.060579s
Loss: 0.606031 | Acc: 65.17% [ 93555.11/143545] | Train [28709/28709] in 56.460887s
Val Error: Acc 71.5% | Avg loss: 1.057094 in 19.093252s
Test Error: Acc 73.2% | Avg loss: 1.031946 in 19.111426s

Epoch 126, Learning Rate [0.009259748514523656]
-------------------------------
Loss: 0.615091 | Acc: 64.15% [ 23093.82/ 36000] | Train [ 7200/28709] in 56.952829s
Loss: 0.607877 | Acc: 64.98% [ 46784.35/ 72000] | Train [14400/28709] in 57.065625s
Loss: 0.608031 | Acc: 64.86% [ 70052.89/108000] | Train [21600/28709] in 57.066190s
Loss: 0.610675 | Acc: 64.58% [ 92696.86/143545] | Train [28709/28709] in 56.463120s
Val Error: Acc 72.2% | Avg loss: 1.065575 in 19.100681s
Test Error: Acc 74.5% | Avg loss: 1.048194 in 19.114013s

Epoch 127, Learning Rate [0.009042781640478288]
-------------------------------
Loss: 0.609728 | Acc: 64.92% [ 23371.97/ 36000] | Train [ 7200/28709] in 56.943772s
Loss: 0.607080 | Acc: 65.14% [ 46901.08/ 72000] | Train [14400/28709] in 57.057219s
Loss: 0.613218 | Acc: 64.40% [ 69547.99/108000] | Train [21600/28709] in 57.056488s
Loss: 0.613384 | Acc: 64.37% [ 92397.33/143545] | Train [28709/28709] in 56.461207s
Val Error: Acc 72.1% | Avg loss: 1.048795 in 19.100260s
Test Error: Acc 73.6% | Avg loss: 1.032598 in 19.112283s

Epoch 128, Learning Rate [0.008827284620923368]
-------------------------------
Loss: 0.613034 | Acc: 64.47% [ 23210.69/ 36000] | Train [ 7200/28709] in 56.959482s
Loss: 0.609880 | Acc: 64.81% [ 46661.14/ 72000] | Train [14400/28709] in 57.058636s
Loss: 0.612038 | Acc: 64.57% [ 69733.52/108000] | Train [21600/28709] in 57.061371s
Loss: 0.610763 | Acc: 64.70% [ 92872.81/143545] | Train [28709/28709] in 56.459837s
Val Error: Acc 72.1% | Avg loss: 1.048956 in 19.103477s
Test Error: Acc 73.6% | Avg loss: 1.026961 in 19.109169s

Epoch 129, Learning Rate [0.00861331062652391]
-------------------------------
Loss: 0.620131 | Acc: 64.03% [ 23051.67/ 36000] | Train [ 7200/28709] in 56.954388s
Loss: 0.620116 | Acc: 63.89% [ 46002.40/ 72000] | Train [14400/28709] in 57.065679s
Loss: 0.613003 | Acc: 64.54% [ 69706.45/108000] | Train [21600/28709] in 57.068836s
Loss: 0.613976 | Acc: 64.44% [ 92495.81/143545] | Train [28709/28709] in 56.467419s
Val Error: Acc 72.3% | Avg loss: 1.051077 in 19.087516s
Test Error: Acc 74.2% | Avg loss: 1.026083 in 19.105875s

Epoch 130, Learning Rate [0.008400912452161272]
-------------------------------
Loss: 0.615470 | Acc: 64.27% [ 23138.15/ 36000] | Train [ 7200/28709] in 57.032787s
Loss: 0.607457 | Acc: 65.11% [ 46879.25/ 72000] | Train [14400/28709] in 57.127987s
Loss: 0.607070 | Acc: 65.05% [ 70256.74/108000] | Train [21600/28709] in 57.123100s
Loss: 0.608177 | Acc: 64.90% [ 93161.87/143545] | Train [28709/28709] in 56.524142s
Val Error: Acc 72.0% | Avg loss: 1.064629 in 19.036844s
Test Error: Acc 73.2% | Avg loss: 1.035540 in 19.067063s

Epoch 131, Learning Rate [0.0081901425039068]
-------------------------------
Loss: 0.598533 | Acc: 66.19% [ 23826.86/ 36000] | Train [ 7200/28709] in 57.025520s
Loss: 0.603110 | Acc: 65.49% [ 47155.11/ 72000] | Train [14400/28709] in 57.128230s
Loss: 0.602449 | Acc: 65.56% [ 70799.43/108000] | Train [21600/28709] in 57.127995s
Loss: 0.601822 | Acc: 65.64% [ 94222.04/143545] | Train [28709/28709] in 56.525827s
Val Error: Acc 72.0% | Avg loss: 1.059500 in 19.043112s
Test Error: Acc 73.9% | Avg loss: 1.034422 in 19.069764s

Epoch 132, Learning Rate [0.007981052786091403]
-------------------------------
Loss: 0.607820 | Acc: 65.00% [ 23399.28/ 36000] | Train [ 7200/28709] in 57.017359s
Loss: 0.605700 | Acc: 65.26% [ 46990.42/ 72000] | Train [14400/28709] in 57.132956s
Loss: 0.606833 | Acc: 65.19% [ 70401.83/108000] | Train [21600/28709] in 57.125532s
Loss: 0.602941 | Acc: 65.54% [ 94078.92/143545] | Train [28709/28709] in 56.525136s
Val Error: Acc 71.5% | Avg loss: 1.069669 in 19.039007s
Test Error: Acc 73.9% | Avg loss: 1.043692 in 19.072135s

Epoch 133, Learning Rate [0.007773694888474269]
-------------------------------
Loss: 0.597044 | Acc: 66.16% [ 23818.42/ 36000] | Train [ 7200/28709] in 57.017633s
Loss: 0.596952 | Acc: 66.15% [ 47629.60/ 72000] | Train [14400/28709] in 57.129359s
Loss: 0.597655 | Acc: 66.10% [ 71383.79/108000] | Train [21600/28709] in 57.132674s
Loss: 0.593891 | Acc: 66.48% [ 95424.05/143545] | Train [28709/28709] in 56.517888s
Val Error: Acc 72.2% | Avg loss: 1.063372 in 19.056122s
Test Error: Acc 73.1% | Avg loss: 1.042099 in 19.079647s

Epoch 134, Learning Rate [0.007568119973513887]
-------------------------------
Loss: 0.597018 | Acc: 66.32% [ 23874.60/ 36000] | Train [ 7200/28709] in 57.018391s
Loss: 0.595331 | Acc: 66.42% [ 47819.39/ 72000] | Train [14400/28709] in 57.135900s
Loss: 0.597031 | Acc: 66.21% [ 71511.57/108000] | Train [21600/28709] in 57.139207s
Loss: 0.596110 | Acc: 66.31% [ 95186.06/143545] | Train [28709/28709] in 56.524075s
Val Error: Acc 71.5% | Avg loss: 1.073182 in 19.053642s
Test Error: Acc 73.6% | Avg loss: 1.042758 in 19.087684s

Epoch 135, Learning Rate [0.007364378763744431]
-------------------------------
Loss: 0.596060 | Acc: 66.22% [ 23839.17/ 36000] | Train [ 7200/28709] in 57.030962s
Loss: 0.599692 | Acc: 65.86% [ 47417.36/ 72000] | Train [14400/28709] in 57.133289s
Loss: 0.598990 | Acc: 66.02% [ 71304.28/108000] | Train [21600/28709] in 57.135192s
Loss: 0.601354 | Acc: 65.73% [ 94357.85/143545] | Train [28709/28709] in 56.534087s
Val Error: Acc 71.3% | Avg loss: 1.074338 in 19.047655s
Test Error: Acc 73.4% | Avg loss: 1.046082 in 19.075848s

Epoch 136, Learning Rate [0.007162521529260769]
-------------------------------
Loss: 0.607690 | Acc: 65.20% [ 23471.68/ 36000] | Train [ 7200/28709] in 57.017184s
Loss: 0.602931 | Acc: 65.66% [ 47273.42/ 72000] | Train [14400/28709] in 57.124224s
Loss: 0.600507 | Acc: 65.92% [ 71198.34/108000] | Train [21600/28709] in 57.129284s
Loss: 0.598058 | Acc: 66.18% [ 95000.23/143545] | Train [28709/28709] in 56.541674s
Val Error: Acc 71.8% | Avg loss: 1.063624 in 19.062665s
Test Error: Acc 74.2% | Avg loss: 1.033195 in 19.085580s

Epoch 137, Learning Rate [0.006962598075315047]
-------------------------------
Loss: 0.588165 | Acc: 67.30% [ 24228.57/ 36000] | Train [ 7200/28709] in 57.096303s
Loss: 0.591843 | Acc: 66.69% [ 48013.78/ 72000] | Train [14400/28709] in 57.131072s
Loss: 0.593770 | Acc: 66.45% [ 71769.10/108000] | Train [21600/28709] in 57.128715s
Loss: 0.596071 | Acc: 66.18% [ 95001.07/143545] | Train [28709/28709] in 56.531586s
Val Error: Acc 71.9% | Avg loss: 1.067146 in 19.054592s
Test Error: Acc 74.4% | Avg loss: 1.031508 in 19.071867s

Epoch 138, Learning Rate [0.006764657730028022]
-------------------------------
Loss: 0.606379 | Acc: 65.27% [ 23495.66/ 36000] | Train [ 7200/28709] in 57.015978s
Loss: 0.598097 | Acc: 66.11% [ 47600.77/ 72000] | Train [14400/28709] in 57.127318s
Loss: 0.597552 | Acc: 66.10% [ 71390.99/108000] | Train [21600/28709] in 57.123662s
Loss: 0.594373 | Acc: 66.40% [ 95309.30/143545] | Train [28709/28709] in 56.534387s
Val Error: Acc 72.2% | Avg loss: 1.066399 in 19.058711s
Test Error: Acc 73.9% | Avg loss: 1.031243 in 19.074548s

Epoch 139, Learning Rate [0.00656874933221804]
-------------------------------
Loss: 0.583752 | Acc: 67.63% [ 24347.86/ 36000] | Train [ 7200/28709] in 57.019866s
Loss: 0.597656 | Acc: 66.17% [ 47642.06/ 72000] | Train [14400/28709] in 57.123490s
Loss: 0.598896 | Acc: 66.03% [ 71316.48/108000] | Train [21600/28709] in 57.128237s
Loss: 0.601841 | Acc: 65.70% [ 94306.55/143545] | Train [28709/28709] in 56.522507s
Val Error: Acc 72.2% | Avg loss: 1.059350 in 19.069672s
Test Error: Acc 74.1% | Avg loss: 1.029676 in 19.076215s

Epoch 140, Learning Rate [0.006374921219350822]
-------------------------------
Loss: 0.592569 | Acc: 66.69% [ 24009.27/ 36000] | Train [ 7200/28709] in 57.018766s
Loss: 0.593565 | Acc: 66.54% [ 47911.33/ 72000] | Train [14400/28709] in 57.135907s
Loss: 0.591683 | Acc: 66.75% [ 72086.78/108000] | Train [21600/28709] in 57.132994s
Loss: 0.590665 | Acc: 66.89% [ 96016.06/143545] | Train [28709/28709] in 56.529302s
Val Error: Acc 71.9% | Avg loss: 1.069546 in 19.061251s
Test Error: Acc 73.6% | Avg loss: 1.042275 in 19.065726s

Epoch 141, Learning Rate [0.006183221215612905]
-------------------------------
Loss: 0.599287 | Acc: 65.92% [ 23732.96/ 36000] | Train [ 7200/28709] in 57.022283s
Loss: 0.599259 | Acc: 65.91% [ 47454.43/ 72000] | Train [14400/28709] in 57.569024s
Loss: 0.600808 | Acc: 65.84% [ 71104.96/108000] | Train [21600/28709] in 58.285276s
Loss: 0.600483 | Acc: 65.87% [ 94551.99/143545] | Train [28709/28709] in 58.244180s
Val Error: Acc 72.4% | Avg loss: 1.056743 in 19.310845s
Test Error: Acc 73.9% | Avg loss: 1.031780 in 19.472433s

Epoch 142, Learning Rate [0.005993696620111742]
-------------------------------
Loss: 0.581840 | Acc: 67.88% [ 24438.49/ 36000] | Train [ 7200/28709] in 59.925229s
Loss: 0.587940 | Acc: 67.21% [ 48393.20/ 72000] | Train [14400/28709] in 60.097263s
Loss: 0.588988 | Acc: 67.14% [ 72512.68/108000] | Train [21600/28709] in 60.285167s
Loss: 0.590610 | Acc: 66.95% [ 96107.92/143545] | Train [28709/28709] in 57.547823s
Val Error: Acc 71.6% | Avg loss: 1.063605 in 19.252756s
Test Error: Acc 73.6% | Avg loss: 1.043654 in 19.345381s

Epoch 143, Learning Rate [0.005806394195205351]
-------------------------------
Loss: 0.581810 | Acc: 68.20% [ 24552.76/ 36000] | Train [ 7200/28709] in 58.470170s
Loss: 0.585962 | Acc: 67.61% [ 48682.55/ 72000] | Train [14400/28709] in 60.008096s
Loss: 0.589245 | Acc: 67.11% [ 72475.83/108000] | Train [21600/28709] in 57.212333s
Loss: 0.588668 | Acc: 67.21% [ 96479.68/143545] | Train [28709/28709] in 56.746320s
Val Error: Acc 72.4% | Avg loss: 1.065971 in 19.186164s
Test Error: Acc 73.6% | Avg loss: 1.037188 in 19.161977s

Epoch 144, Learning Rate [0.005621360154964422]
-------------------------------
Loss: 0.590388 | Acc: 66.70% [ 24011.86/ 36000] | Train [ 7200/28709] in 58.535664s
Loss: 0.587289 | Acc: 67.11% [ 48315.89/ 72000] | Train [14400/28709] in 58.542155s
Loss: 0.587138 | Acc: 67.18% [ 72552.21/108000] | Train [21600/28709] in 60.302975s
Loss: 0.585990 | Acc: 67.27% [ 96558.28/143545] | Train [28709/28709] in 58.843987s
Val Error: Acc 72.4% | Avg loss: 1.062560 in 19.818374s
Test Error: Acc 74.5% | Avg loss: 1.037891 in 19.633878s

Epoch 145, Learning Rate [0.005438640153769654]
-------------------------------
Loss: 0.584470 | Acc: 67.85% [ 24426.72/ 36000] | Train [ 7200/28709] in 59.322259s
Loss: 0.588163 | Acc: 67.33% [ 48480.56/ 72000] | Train [14400/28709] in 58.558386s
Loss: 0.586749 | Acc: 67.37% [ 72763.07/108000] | Train [21600/28709] in 58.430977s
Loss: 0.586306 | Acc: 67.41% [ 96770.56/143545] | Train [28709/28709] in 57.025085s
Val Error: Acc 72.1% | Avg loss: 1.066101 in 18.828426s
Test Error: Acc 73.9% | Avg loss: 1.042589 in 18.831346s

Epoch 146, Learning Rate [0.0052582792750472465]
-------------------------------
Loss: 0.583747 | Acc: 67.70% [ 24372.29/ 36000] | Train [ 7200/28709] in 57.007456s
Loss: 0.585497 | Acc: 67.41% [ 48535.57/ 72000] | Train [14400/28709] in 57.116050s
Loss: 0.583892 | Acc: 67.55% [ 72952.71/108000] | Train [21600/28709] in 57.107207s
Loss: 0.584701 | Acc: 67.49% [ 96882.30/143545] | Train [28709/28709] in 56.527072s
Val Error: Acc 72.8% | Avg loss: 1.060732 in 18.826338s
Test Error: Acc 74.1% | Avg loss: 1.031675 in 18.843022s
current highest Acc: 72.8%

Epoch 147, Learning Rate [0.005080322020145224]
-------------------------------
Loss: 0.574676 | Acc: 68.94% [ 24820.20/ 36000] | Train [ 7200/28709] in 57.001053s
Loss: 0.581855 | Acc: 68.08% [ 49016.84/ 72000] | Train [14400/28709] in 58.006927s
Loss: 0.579917 | Acc: 68.22% [ 73680.10/108000] | Train [21600/28709] in 58.232651s
Loss: 0.582650 | Acc: 67.90% [ 97461.45/143545] | Train [28709/28709] in 57.056522s
Val Error: Acc 72.1% | Avg loss: 1.060292 in 18.751044s
Test Error: Acc 73.8% | Avg loss: 1.033756 in 18.730354s

Epoch 148, Learning Rate [0.0049048122973533986]
-------------------------------
Loss: 0.593603 | Acc: 66.98% [ 24113.95/ 36000] | Train [ 7200/28709] in 57.258786s
Loss: 0.584671 | Acc: 67.75% [ 48779.23/ 72000] | Train [14400/28709] in 57.381701s
Loss: 0.586058 | Acc: 67.54% [ 72945.92/108000] | Train [21600/28709] in 57.388663s
Loss: 0.585571 | Acc: 67.58% [ 97003.31/143545] | Train [28709/28709] in 56.747390s
Val Error: Acc 72.8% | Avg loss: 1.066990 in 18.718301s
Test Error: Acc 74.3% | Avg loss: 1.044621 in 18.832278s
current highest Acc: 72.8%

Epoch 149, Learning Rate [0.004731793411069669]
-------------------------------
Loss: 0.579662 | Acc: 68.13% [ 24528.34/ 36000] | Train [ 7200/28709] in 57.307318s
Loss: 0.580179 | Acc: 68.01% [ 48970.67/ 72000] | Train [14400/28709] in 57.569403s
Loss: 0.583322 | Acc: 67.78% [ 73200.66/108000] | Train [21600/28709] in 58.174293s
Loss: 0.584695 | Acc: 67.60% [ 97029.36/143545] | Train [28709/28709] in 57.623857s
Val Error: Acc 72.5% | Avg loss: 1.073765 in 19.318715s
Test Error: Acc 73.4% | Avg loss: 1.054976 in 19.383898s

Epoch 150, Learning Rate [0.004561308051115286]
-------------------------------
Loss: 0.577083 | Acc: 68.14% [ 24530.24/ 36000] | Train [ 7200/28709] in 58.074209s
Loss: 0.583963 | Acc: 67.72% [ 48758.52/ 72000] | Train [14400/28709] in 58.200597s
Loss: 0.581181 | Acc: 68.04% [ 73485.17/108000] | Train [21600/28709] in 58.245172s
Loss: 0.581097 | Acc: 68.03% [ 97658.87/143545] | Train [28709/28709] in 57.614410s
Val Error: Acc 72.1% | Avg loss: 1.064872 in 19.333454s
Test Error: Acc 73.9% | Avg loss: 1.036384 in 19.334263s

Epoch 151, Learning Rate [0.004393398282201789]
-------------------------------
Loss: 0.575676 | Acc: 68.57% [ 24684.70/ 36000] | Train [ 7200/28709] in 58.094486s
Loss: 0.580532 | Acc: 68.08% [ 49020.20/ 72000] | Train [14400/28709] in 58.206542s
Loss: 0.581144 | Acc: 68.04% [ 73481.05/108000] | Train [21600/28709] in 58.207562s
Loss: 0.583841 | Acc: 67.74% [ 97237.98/143545] | Train [28709/28709] in 57.615895s
Val Error: Acc 72.4% | Avg loss: 1.057882 in 19.309697s
Test Error: Acc 74.0% | Avg loss: 1.034144 in 19.335570s

Epoch 152, Learning Rate [0.00422810553355217]
-------------------------------
Loss: 0.567549 | Acc: 69.48% [ 25014.35/ 36000] | Train [ 7200/28709] in 58.175722s
Loss: 0.573189 | Acc: 68.89% [ 49603.27/ 72000] | Train [14400/28709] in 58.346020s
Loss: 0.574347 | Acc: 68.70% [ 74199.54/108000] | Train [21600/28709] in 58.359312s
Loss: 0.577048 | Acc: 68.39% [ 98176.08/143545] | Train [28709/28709] in 57.740104s
Val Error: Acc 72.4% | Avg loss: 1.059662 in 19.334772s
Test Error: Acc 74.1% | Avg loss: 1.030218 in 19.356556s

Epoch 153, Learning Rate [0.00406547058867883]
-------------------------------
Loss: 0.582002 | Acc: 68.00% [ 24479.04/ 36000] | Train [ 7200/28709] in 58.238590s
Loss: 0.582482 | Acc: 68.00% [ 48957.50/ 72000] | Train [14400/28709] in 58.334286s
Loss: 0.580264 | Acc: 68.20% [ 73651.08/108000] | Train [21600/28709] in 58.376550s
Loss: 0.578442 | Acc: 68.36% [ 98133.51/143545] | Train [28709/28709] in 57.746703s
Val Error: Acc 72.1% | Avg loss: 1.062663 in 19.395300s
Test Error: Acc 73.7% | Avg loss: 1.039967 in 19.351192s

Epoch 154, Learning Rate [0.003905533575320855]
-------------------------------
Loss: 0.578752 | Acc: 68.36% [ 24609.63/ 36000] | Train [ 7200/28709] in 58.243493s
Loss: 0.572022 | Acc: 69.04% [ 49708.96/ 72000] | Train [14400/28709] in 58.337329s
Loss: 0.575947 | Acc: 68.66% [ 74147.57/108000] | Train [21600/28709] in 58.364852s
Loss: 0.577885 | Acc: 68.45% [ 98256.14/143545] | Train [28709/28709] in 57.776486s
Val Error: Acc 72.7% | Avg loss: 1.057632 in 19.347809s
Test Error: Acc 74.3% | Avg loss: 1.036128 in 19.349237s

Epoch 155, Learning Rate [0.0037483339555431077]
-------------------------------
Loss: 0.593587 | Acc: 66.79% [ 24046.19/ 36000] | Train [ 7200/28709] in 58.221913s
Loss: 0.586338 | Acc: 67.56% [ 48645.77/ 72000] | Train [14400/28709] in 58.352531s
Loss: 0.581896 | Acc: 68.00% [ 73436.84/108000] | Train [21600/28709] in 58.362087s
Loss: 0.581276 | Acc: 68.03% [ 97655.83/143545] | Train [28709/28709] in 57.769808s
Val Error: Acc 72.7% | Avg loss: 1.054111 in 19.385790s
Test Error: Acc 74.4% | Avg loss: 1.032217 in 19.314135s

Epoch 156, Learning Rate [0.003593910515999536]
-------------------------------
Loss: 0.568928 | Acc: 69.38% [ 24977.91/ 36000] | Train [ 7200/28709] in 58.267895s
Loss: 0.568866 | Acc: 69.34% [ 49922.04/ 72000] | Train [14400/28709] in 58.384441s
Loss: 0.565686 | Acc: 69.67% [ 75243.52/108000] | Train [21600/28709] in 58.377192s
Loss: 0.567684 | Acc: 69.42% [ 99645.87/143545] | Train [28709/28709] in 57.922179s
Val Error: Acc 72.5% | Avg loss: 1.063608 in 19.412399s
Test Error: Acc 73.5% | Avg loss: 1.043379 in 19.435122s

Epoch 157, Learning Rate [0.003442301358363163]
-------------------------------
Loss: 0.583808 | Acc: 67.82% [ 24416.53/ 36000] | Train [ 7200/28709] in 58.288826s
Loss: 0.586684 | Acc: 67.51% [ 48607.57/ 72000] | Train [14400/28709] in 58.391929s
Loss: 0.577380 | Acc: 68.43% [ 73907.74/108000] | Train [21600/28709] in 58.387745s
Loss: 0.577653 | Acc: 68.41% [ 98197.89/143545] | Train [28709/28709] in 57.803917s
Val Error: Acc 72.5% | Avg loss: 1.068023 in 19.343623s
Test Error: Acc 73.9% | Avg loss: 1.045640 in 19.365634s

Epoch 158, Learning Rate [0.0032935438899250563]
-------------------------------
Loss: 0.561270 | Acc: 70.20% [ 25271.74/ 36000] | Train [ 7200/28709] in 58.257539s
Loss: 0.571477 | Acc: 68.95% [ 49645.75/ 72000] | Train [14400/28709] in 58.398117s
Loss: 0.573379 | Acc: 68.72% [ 74222.50/108000] | Train [21600/28709] in 58.409246s
Loss: 0.573676 | Acc: 68.75% [ 98684.38/143545] | Train [28709/28709] in 57.806663s
Val Error: Acc 72.7% | Avg loss: 1.054262 in 19.335866s
Test Error: Acc 74.3% | Avg loss: 1.037266 in 19.346138s

Epoch 159, Learning Rate [0.003147674814364644]
-------------------------------
Loss: 0.574985 | Acc: 69.05% [ 24859.75/ 36000] | Train [ 7200/28709] in 58.273126s
Loss: 0.573214 | Acc: 69.08% [ 49739.88/ 72000] | Train [14400/28709] in 58.370832s
Loss: 0.571694 | Acc: 69.17% [ 74703.56/108000] | Train [21600/28709] in 58.421620s
Loss: 0.569810 | Acc: 69.33% [ 99523.32/143545] | Train [28709/28709] in 57.800790s
Val Error: Acc 72.8% | Avg loss: 1.066198 in 19.336282s
Test Error: Acc 74.1% | Avg loss: 1.039984 in 19.322814s

Epoch 160, Learning Rate [0.0030047301226936427]
-------------------------------
Loss: 0.565939 | Acc: 69.54% [ 25033.20/ 36000] | Train [ 7200/28709] in 58.266057s
Loss: 0.564425 | Acc: 69.73% [ 50202.32/ 72000] | Train [14400/28709] in 58.403134s
Loss: 0.568709 | Acc: 69.31% [ 74858.16/108000] | Train [21600/28709] in 58.395436s
Loss: 0.570149 | Acc: 69.18% [ 99297.65/143545] | Train [28709/28709] in 57.797060s
Val Error: Acc 73.0% | Avg loss: 1.069156 in 19.332673s
Test Error: Acc 74.6% | Avg loss: 1.045603 in 19.331274s
current highest Acc: 73.0%

Epoch 161, Learning Rate [0.0028647450843757895]
-------------------------------
Loss: 0.564135 | Acc: 69.94% [ 25178.05/ 36000] | Train [ 7200/28709] in 58.250124s
Loss: 0.572688 | Acc: 69.00% [ 49681.63/ 72000] | Train [14400/28709] in 58.371268s
Loss: 0.574332 | Acc: 68.86% [ 74370.80/108000] | Train [21600/28709] in 58.399852s
Loss: 0.574828 | Acc: 68.76% [ 98701.24/143545] | Train [28709/28709] in 57.795270s
Val Error: Acc 72.8% | Avg loss: 1.050258 in 19.352471s
Test Error: Acc 74.0% | Avg loss: 1.027376 in 19.327302s

Epoch 162, Learning Rate [0.00272775423862465]
-------------------------------
Loss: 0.574603 | Acc: 68.84% [ 24780.68/ 36000] | Train [ 7200/28709] in 58.229096s
Loss: 0.573095 | Acc: 68.82% [ 49549.49/ 72000] | Train [14400/28709] in 58.380396s
Loss: 0.573496 | Acc: 68.71% [ 74204.04/108000] | Train [21600/28709] in 58.388978s
Loss: 0.574451 | Acc: 68.60% [ 98469.65/143545] | Train [28709/28709] in 57.805432s
Val Error: Acc 72.4% | Avg loss: 1.058981 in 19.334754s
Test Error: Acc 74.4% | Avg loss: 1.029526 in 19.336381s

Epoch 163, Learning Rate [0.002593791385881575]
-------------------------------
Loss: 0.579323 | Acc: 68.53% [ 24669.02/ 36000] | Train [ 7200/28709] in 58.250591s
Loss: 0.576938 | Acc: 68.48% [ 49302.29/ 72000] | Train [14400/28709] in 58.416672s
Loss: 0.576231 | Acc: 68.53% [ 74012.31/108000] | Train [21600/28709] in 58.386497s
Loss: 0.576250 | Acc: 68.52% [ 98360.43/143545] | Train [28709/28709] in 57.801531s
Val Error: Acc 72.9% | Avg loss: 1.055533 in 19.328100s
Test Error: Acc 74.0% | Avg loss: 1.031172 in 19.346159s

Epoch 164, Learning Rate [0.0024628895794759484]
-------------------------------
Loss: 0.572739 | Acc: 68.95% [ 24820.79/ 36000] | Train [ 7200/28709] in 58.252486s
Loss: 0.568203 | Acc: 69.51% [ 50047.81/ 72000] | Train [14400/28709] in 58.415236s
Loss: 0.566006 | Acc: 69.69% [ 75261.77/108000] | Train [21600/28709] in 58.374280s
Loss: 0.568489 | Acc: 69.41% [ 99630.26/143545] | Train [28709/28709] in 57.772715s
Val Error: Acc 72.5% | Avg loss: 1.063778 in 19.341401s
Test Error: Acc 74.5% | Avg loss: 1.031201 in 19.366980s

Epoch 165, Learning Rate [0.0023350811174697762]
-------------------------------
Loss: 0.561936 | Acc: 70.14% [ 25250.41/ 36000] | Train [ 7200/28709] in 58.209197s
Loss: 0.567930 | Acc: 69.46% [ 50008.06/ 72000] | Train [14400/28709] in 57.884591s
Loss: 0.566630 | Acc: 69.58% [ 75146.96/108000] | Train [21600/28709] in 57.605475s
Loss: 0.566687 | Acc: 69.65% [ 99973.04/143545] | Train [28709/28709] in 57.037615s
Val Error: Acc 72.2% | Avg loss: 1.085907 in 18.836835s
Test Error: Acc 74.7% | Avg loss: 1.053233 in 18.893911s

Epoch 166, Learning Rate [0.00221039753468862]
-------------------------------
Loss: 0.556716 | Acc: 70.75% [ 25469.37/ 36000] | Train [ 7200/28709] in 57.188246s
Loss: 0.564271 | Acc: 69.93% [ 50348.43/ 72000] | Train [14400/28709] in 57.160952s
Loss: 0.562097 | Acc: 70.13% [ 75738.49/108000] | Train [21600/28709] in 57.151134s
Loss: 0.566651 | Acc: 69.63% [ 99943.25/143545] | Train [28709/28709] in 57.253389s
Val Error: Acc 72.5% | Avg loss: 1.064964 in 19.019475s
Test Error: Acc 74.7% | Avg loss: 1.037758 in 19.015175s

Epoch 167, Learning Rate [0.002088869594940843]
-------------------------------
Loss: 0.559803 | Acc: 70.50% [ 25378.25/ 36000] | Train [ 7200/28709] in 57.619638s
Loss: 0.560062 | Acc: 70.39% [ 50678.42/ 72000] | Train [14400/28709] in 57.610070s
Loss: 0.562705 | Acc: 70.14% [ 75749.38/108000] | Train [21600/28709] in 57.620076s
Loss: 0.563295 | Acc: 70.10% [100630.52/143545] | Train [28709/28709] in 57.113204s
Val Error: Acc 72.7% | Avg loss: 1.061042 in 19.343323s
Test Error: Acc 74.2% | Avg loss: 1.033573 in 19.099766s

Epoch 168, Learning Rate [0.0019705272834271296]
-------------------------------
Loss: 0.565433 | Acc: 69.69% [ 25087.85/ 36000] | Train [ 7200/28709] in 57.689183s
Loss: 0.571497 | Acc: 69.15% [ 49785.60/ 72000] | Train [14400/28709] in 58.528355s
Loss: 0.570139 | Acc: 69.28% [ 74818.36/108000] | Train [21600/28709] in 58.187880s
Loss: 0.566031 | Acc: 69.71% [100064.55/143545] | Train [28709/28709] in 57.698091s
Val Error: Acc 72.4% | Avg loss: 1.058012 in 19.215641s
Test Error: Acc 74.1% | Avg loss: 1.028938 in 19.197465s

Epoch 169, Learning Rate [0.0018553997993420454]
-------------------------------
Loss: 0.564309 | Acc: 70.04% [ 25212.65/ 36000] | Train [ 7200/28709] in 57.916150s
Loss: 0.564906 | Acc: 69.98% [ 50387.86/ 72000] | Train [14400/28709] in 58.278019s
Loss: 0.564358 | Acc: 69.99% [ 75587.32/108000] | Train [21600/28709] in 57.995933s
Loss: 0.561740 | Acc: 70.25% [100843.48/143545] | Train [28709/28709] in 57.357672s
Val Error: Acc 72.8% | Avg loss: 1.066794 in 19.266933s
Test Error: Acc 74.4% | Avg loss: 1.040130 in 19.218280s

Epoch 170, Learning Rate [0.0017435155486695973]
-------------------------------
Loss: 0.569209 | Acc: 69.36% [ 24971.13/ 36000] | Train [ 7200/28709] in 58.073030s
Loss: 0.565619 | Acc: 69.70% [ 50187.29/ 72000] | Train [14400/28709] in 58.157643s
Loss: 0.564429 | Acc: 69.89% [ 75483.67/108000] | Train [21600/28709] in 57.707143s
Loss: 0.562820 | Acc: 70.08% [100596.00/143545] | Train [28709/28709] in 57.547154s
Val Error: Acc 72.6% | Avg loss: 1.061775 in 19.327739s
Test Error: Acc 74.3% | Avg loss: 1.033402 in 19.152412s

Epoch 171, Learning Rate [0.0016349021371744826]
-------------------------------
Loss: 0.562429 | Acc: 70.11% [ 25238.75/ 36000] | Train [ 7200/28709] in 57.829746s
Loss: 0.559993 | Acc: 70.34% [ 50644.03/ 72000] | Train [14400/28709] in 58.392648s
Loss: 0.556978 | Acc: 70.67% [ 76327.36/108000] | Train [21600/28709] in 58.071642s
Loss: 0.560745 | Acc: 70.25% [100833.41/143545] | Train [28709/28709] in 57.737332s
Val Error: Acc 72.4% | Avg loss: 1.058837 in 19.233682s
Test Error: Acc 74.4% | Avg loss: 1.032765 in 19.146281s

Epoch 172, Learning Rate [0.0015295863635907665]
-------------------------------
Loss: 0.557502 | Acc: 70.64% [ 25428.82/ 36000] | Train [ 7200/28709] in 58.296585s
Loss: 0.552589 | Acc: 71.12% [ 51205.79/ 72000] | Train [14400/28709] in 58.445142s
Loss: 0.556387 | Acc: 70.76% [ 76417.28/108000] | Train [21600/28709] in 58.514807s
Loss: 0.558038 | Acc: 70.58% [101318.35/143545] | Train [28709/28709] in 57.377615s
Val Error: Acc 72.4% | Avg loss: 1.072070 in 19.232991s
Test Error: Acc 74.4% | Avg loss: 1.044383 in 19.180528s

Epoch 173, Learning Rate [0.0014275942130097092]
-------------------------------
Loss: 0.562153 | Acc: 70.12% [ 25242.58/ 36000] | Train [ 7200/28709] in 58.560735s
Loss: 0.570068 | Acc: 69.25% [ 49857.55/ 72000] | Train [14400/28709] in 60.956070s
Loss: 0.570253 | Acc: 69.23% [ 74772.68/108000] | Train [21600/28709] in 58.287620s
Loss: 0.568932 | Acc: 69.44% [ 99673.14/143545] | Train [28709/28709] in 57.505506s
Val Error: Acc 72.6% | Avg loss: 1.063720 in 34.545473s
Test Error: Acc 74.3% | Avg loss: 1.035313 in 34.400920s

Epoch 174, Learning Rate [0.0013289508504683236]
-------------------------------
Loss: 0.553073 | Acc: 71.21% [ 25636.07/ 36000] | Train [ 7200/28709] in 57.971658s
Loss: 0.557134 | Acc: 70.83% [ 50998.58/ 72000] | Train [14400/28709] in 58.264012s
Loss: 0.557313 | Acc: 70.80% [ 76464.56/108000] | Train [21600/28709] in 58.660900s
Loss: 0.556682 | Acc: 70.84% [101686.10/143545] | Train [28709/28709] in 58.099103s
Val Error: Acc 72.3% | Avg loss: 1.066715 in 34.568525s
Test Error: Acc 74.3% | Avg loss: 1.038283 in 34.458244s

Epoch 175, Learning Rate [0.0012336806147402858]
-------------------------------
Loss: 0.580018 | Acc: 68.40% [ 24624.91/ 36000] | Train [ 7200/28709] in 58.304588s
Loss: 0.570570 | Acc: 69.37% [ 49942.83/ 72000] | Train [14400/28709] in 58.348175s
Loss: 0.567911 | Acc: 69.61% [ 75174.31/108000] | Train [21600/28709] in 58.558671s
Loss: 0.566770 | Acc: 69.70% [100043.71/143545] | Train [28709/28709] in 57.618038s
Val Error: Acc 72.6% | Avg loss: 1.064184 in 34.304616s
Test Error: Acc 74.5% | Avg loss: 1.036041 in 34.312125s

Epoch 176, Learning Rate [0.0011418070123307019]
-------------------------------
Loss: 0.573381 | Acc: 69.10% [ 24874.98/ 36000] | Train [ 7200/28709] in 58.051629s
Loss: 0.573311 | Acc: 68.97% [ 49661.89/ 72000] | Train [14400/28709] in 57.094124s
Loss: 0.566634 | Acc: 69.72% [ 75298.54/108000] | Train [21600/28709] in 57.117136s
Loss: 0.565842 | Acc: 69.76% [100138.78/143545] | Train [28709/28709] in 56.542479s
Val Error: Acc 72.4% | Avg loss: 1.065165 in 18.598323s
Test Error: Acc 74.7% | Avg loss: 1.037218 in 18.594231s

Epoch 177, Learning Rate [0.0010533527116762295]
-------------------------------
Loss: 0.568156 | Acc: 69.72% [ 25099.81/ 36000] | Train [ 7200/28709] in 57.013246s
Loss: 0.559429 | Acc: 70.47% [ 50737.40/ 72000] | Train [14400/28709] in 57.118938s
Loss: 0.563091 | Acc: 70.12% [ 75724.26/108000] | Train [21600/28709] in 57.118289s
Loss: 0.566149 | Acc: 69.79% [100174.49/143545] | Train [28709/28709] in 56.518810s
Val Error: Acc 72.6% | Avg loss: 1.053165 in 18.599348s
Test Error: Acc 74.5% | Avg loss: 1.023206 in 18.594729s

Epoch 178, Learning Rate [0.0009683395375519891]
-------------------------------
Loss: 0.552575 | Acc: 70.99% [ 25556.94/ 36000] | Train [ 7200/28709] in 56.995293s
Loss: 0.549707 | Acc: 71.31% [ 51346.38/ 72000] | Train [14400/28709] in 57.120947s
Loss: 0.554696 | Acc: 70.83% [ 76492.99/108000] | Train [21600/28709] in 57.124823s
Loss: 0.557760 | Acc: 70.50% [101194.55/143545] | Train [28709/28709] in 56.514364s
Val Error: Acc 72.4% | Avg loss: 1.061357 in 18.594712s
Test Error: Acc 74.8% | Avg loss: 1.032417 in 18.598833s

Epoch 179, Learning Rate [0.000886788465686618]
-------------------------------
Loss: 0.558538 | Acc: 70.40% [ 25342.67/ 36000] | Train [ 7200/28709] in 56.987920s
Loss: 0.560812 | Acc: 70.21% [ 50550.09/ 72000] | Train [14400/28709] in 57.119606s
Loss: 0.561150 | Acc: 70.27% [ 75889.21/108000] | Train [21600/28709] in 57.299136s
Loss: 0.561438 | Acc: 70.20% [100763.73/143545] | Train [28709/28709] in 57.155913s
Val Error: Acc 72.2% | Avg loss: 1.068038 in 18.938951s
Test Error: Acc 74.5% | Avg loss: 1.037501 in 18.885831s

Epoch 180, Learning Rate [0.0008087196175868203]
-------------------------------
Loss: 0.567908 | Acc: 69.38% [ 24977.04/ 36000] | Train [ 7200/28709] in 62.335805s
Loss: 0.568013 | Acc: 69.41% [ 49972.86/ 72000] | Train [14400/28709] in 62.424899s
Loss: 0.563334 | Acc: 69.97% [ 75564.21/108000] | Train [21600/28709] in 57.711018s
Loss: 0.560736 | Acc: 70.22% [100804.39/143545] | Train [28709/28709] in 61.197223s
Val Error: Acc 72.5% | Avg loss: 1.057096 in 20.510070s
Test Error: Acc 74.6% | Avg loss: 1.028625 in 19.179219s

Epoch 181, Learning Rate [0.0007341522555726968]
-------------------------------
Loss: 0.553161 | Acc: 71.13% [ 25606.78/ 36000] | Train [ 7200/28709] in 57.102194s
Loss: 0.558548 | Acc: 70.51% [ 50769.37/ 72000] | Train [14400/28709] in 57.248086s
Loss: 0.553725 | Acc: 71.01% [ 76692.55/108000] | Train [21600/28709] in 57.251303s
Loss: 0.558210 | Acc: 70.57% [101296.02/143545] | Train [28709/28709] in 56.757401s
Val Error: Acc 72.1% | Avg loss: 1.061102 in 18.984199s
Test Error: Acc 74.8% | Avg loss: 1.027105 in 19.068398s

Epoch 182, Learning Rate [0.0006631047780250479]
-------------------------------
Loss: 0.549084 | Acc: 71.36% [ 25688.30/ 36000] | Train [ 7200/28709] in 57.438929s
Loss: 0.558647 | Acc: 70.42% [ 50702.31/ 72000] | Train [14400/28709] in 58.876101s
Loss: 0.559602 | Acc: 70.36% [ 75992.98/108000] | Train [21600/28709] in 61.815418s
Loss: 0.557678 | Acc: 70.55% [101270.35/143545] | Train [28709/28709] in 57.844454s
Val Error: Acc 72.3% | Avg loss: 1.061317 in 19.100595s
Test Error: Acc 74.5% | Avg loss: 1.033675 in 19.199454s

Epoch 183, Learning Rate [0.0005955947148458554]
-------------------------------
Loss: 0.558896 | Acc: 70.30% [ 25306.39/ 36000] | Train [ 7200/28709] in 58.559424s
Loss: 0.558048 | Acc: 70.61% [ 50836.56/ 72000] | Train [14400/28709] in 57.291997s
Loss: 0.552911 | Acc: 71.08% [ 76767.75/108000] | Train [21600/28709] in 57.290235s
Loss: 0.555800 | Acc: 70.77% [101593.93/143545] | Train [28709/28709] in 56.674506s
Val Error: Acc 72.6% | Avg loss: 1.056731 in 18.751775s
Test Error: Acc 74.4% | Avg loss: 1.028665 in 18.765665s

Epoch 184, Learning Rate [0.0005316387231330303]
-------------------------------
Loss: 0.552417 | Acc: 71.24% [ 25645.35/ 36000] | Train [ 7200/28709] in 57.132119s
Loss: 0.560722 | Acc: 70.46% [ 50732.29/ 72000] | Train [14400/28709] in 57.296109s
Loss: 0.558093 | Acc: 70.70% [ 76354.67/108000] | Train [21600/28709] in 57.274107s
Loss: 0.560364 | Acc: 70.39% [101044.36/143545] | Train [28709/28709] in 56.676090s
Val Error: Acc 72.4% | Avg loss: 1.062445 in 18.753215s
Test Error: Acc 74.8% | Avg loss: 1.032438 in 18.754394s

Epoch 185, Learning Rate [0.00047125258307053534]
-------------------------------
Loss: 0.560343 | Acc: 70.51% [ 25383.28/ 36000] | Train [ 7200/28709] in 57.141746s
Loss: 0.561003 | Acc: 70.43% [ 50707.63/ 72000] | Train [14400/28709] in 57.280255s
Loss: 0.562873 | Acc: 70.20% [ 75817.94/108000] | Train [21600/28709] in 57.276106s
Loss: 0.562805 | Acc: 70.16% [100716.69/143545] | Train [28709/28709] in 56.675080s
Val Error: Acc 72.6% | Avg loss: 1.059587 in 18.761391s
Test Error: Acc 74.6% | Avg loss: 1.031862 in 18.756971s

Epoch 186, Learning Rate [0.00041445119403485153]
-------------------------------
Loss: 0.539069 | Acc: 72.58% [ 26129.42/ 36000] | Train [ 7200/28709] in 57.118004s
Loss: 0.544646 | Acc: 72.10% [ 51909.50/ 72000] | Train [14400/28709] in 57.279954s
Loss: 0.545795 | Acc: 71.95% [ 77708.66/108000] | Train [21600/28709] in 57.267086s
Loss: 0.547417 | Acc: 71.72% [102951.31/143545] | Train [28709/28709] in 56.660100s
Val Error: Acc 72.4% | Avg loss: 1.060655 in 18.756754s
Test Error: Acc 74.7% | Avg loss: 1.026522 in 18.747130s

Epoch 187, Learning Rate [0.00036124857091879005]
-------------------------------
Loss: 0.549538 | Acc: 71.38% [ 25696.64/ 36000] | Train [ 7200/28709] in 57.131540s
Loss: 0.557520 | Acc: 70.69% [ 50897.64/ 72000] | Train [14400/28709] in 57.273879s
Loss: 0.556750 | Acc: 70.86% [ 76530.81/108000] | Train [21600/28709] in 57.267264s
Loss: 0.556907 | Acc: 70.76% [101568.10/143545] | Train [28709/28709] in 56.671734s
Val Error: Acc 72.2% | Avg loss: 1.059646 in 18.769321s
Test Error: Acc 74.9% | Avg loss: 1.030622 in 18.758818s

Epoch 188, Learning Rate [0.00031165784067351205]
-------------------------------
Loss: 0.562685 | Acc: 70.31% [ 25310.30/ 36000] | Train [ 7200/28709] in 57.135499s
Loss: 0.560560 | Acc: 70.46% [ 50733.84/ 72000] | Train [14400/28709] in 57.264997s
Loss: 0.558001 | Acc: 70.72% [ 76376.41/108000] | Train [21600/28709] in 57.264636s
Loss: 0.557518 | Acc: 70.70% [101489.02/143545] | Train [28709/28709] in 56.718964s
Val Error: Acc 72.4% | Avg loss: 1.059361 in 18.773748s
Test Error: Acc 74.5% | Avg loss: 1.029825 in 18.748993s

Epoch 189, Learning Rate [0.00026569123906966915]
-------------------------------
Loss: 0.562289 | Acc: 70.06% [ 25222.18/ 36000] | Train [ 7200/28709] in 57.128735s
Loss: 0.557297 | Acc: 70.71% [ 50913.60/ 72000] | Train [14400/28709] in 57.278582s
Loss: 0.556811 | Acc: 70.74% [ 76400.26/108000] | Train [21600/28709] in 57.274217s
Loss: 0.555980 | Acc: 70.74% [101543.21/143545] | Train [28709/28709] in 56.671059s
Val Error: Acc 72.4% | Avg loss: 1.061191 in 18.780185s
Test Error: Acc 74.7% | Avg loss: 1.033262 in 18.754426s

Epoch 190, Learning Rate [0.00022336010767839195]
-------------------------------
Loss: 0.555827 | Acc: 70.69% [ 25449.92/ 36000] | Train [ 7200/28709] in 57.159902s
Loss: 0.554687 | Acc: 70.78% [ 50964.46/ 72000] | Train [14400/28709] in 57.289098s
Loss: 0.552199 | Acc: 71.10% [ 76787.07/108000] | Train [21600/28709] in 57.287298s
Loss: 0.553532 | Acc: 70.99% [101901.25/143545] | Train [28709/28709] in 56.678414s
Val Error: Acc 72.4% | Avg loss: 1.056470 in 18.762676s
Test Error: Acc 74.7% | Avg loss: 1.022956 in 18.756649s

Epoch 191, Learning Rate [0.0001846748910729351]
-------------------------------
Loss: 0.551931 | Acc: 71.51% [ 25743.01/ 36000] | Train [ 7200/28709] in 57.134944s
Loss: 0.552304 | Acc: 71.32% [ 51351.82/ 72000] | Train [14400/28709] in 57.270159s
Loss: 0.549575 | Acc: 71.56% [ 77283.90/108000] | Train [21600/28709] in 57.268780s
Loss: 0.549865 | Acc: 71.49% [102615.41/143545] | Train [28709/28709] in 56.677070s
Val Error: Acc 72.4% | Avg loss: 1.062127 in 18.777185s
Test Error: Acc 74.6% | Avg loss: 1.033337 in 18.733313s

Epoch 192, Learning Rate [0.00014964513425163694]
-------------------------------
Loss: 0.557122 | Acc: 70.69% [ 25449.49/ 36000] | Train [ 7200/28709] in 57.140508s
Loss: 0.563451 | Acc: 70.09% [ 50464.44/ 72000] | Train [14400/28709] in 57.277894s
Loss: 0.561406 | Acc: 70.31% [ 75932.88/108000] | Train [21600/28709] in 57.271675s
Loss: 0.558403 | Acc: 70.58% [101316.08/143545] | Train [28709/28709] in 56.672199s
Val Error: Acc 72.6% | Avg loss: 1.058654 in 18.763276s
Test Error: Acc 74.5% | Avg loss: 1.028833 in 18.746562s

Epoch 193, Learning Rate [0.00011827948028283353]
-------------------------------
Loss: 0.539637 | Acc: 72.77% [ 26198.27/ 36000] | Train [ 7200/28709] in 57.146260s
Loss: 0.546828 | Acc: 71.94% [ 51795.68/ 72000] | Train [14400/28709] in 57.290468s
Loss: 0.548936 | Acc: 71.74% [ 77478.01/108000] | Train [21600/28709] in 57.277605s
Loss: 0.553733 | Acc: 71.23% [102243.56/143545] | Train [28709/28709] in 56.682070s
Val Error: Acc 72.5% | Avg loss: 1.055302 in 18.792930s
Test Error: Acc 74.4% | Avg loss: 1.025238 in 18.745076s

Epoch 194, Learning Rate [9.058566817230607e-05]
-------------------------------
Loss: 0.559419 | Acc: 70.47% [ 25369.90/ 36000] | Train [ 7200/28709] in 57.123993s
Loss: 0.558098 | Acc: 70.50% [ 50756.58/ 72000] | Train [14400/28709] in 57.263091s
Loss: 0.559266 | Acc: 70.44% [ 76078.93/108000] | Train [21600/28709] in 57.276332s
Loss: 0.557591 | Acc: 70.67% [101436.89/143545] | Train [28709/28709] in 56.706702s
Val Error: Acc 72.7% | Avg loss: 1.068800 in 18.768549s
Test Error: Acc 74.2% | Avg loss: 1.040722 in 18.738530s

Epoch 195, Learning Rate [6.657053095380006e-05]
-------------------------------
Loss: 0.558864 | Acc: 70.58% [ 25407.59/ 36000] | Train [ 7200/28709] in 57.116637s
Loss: 0.558243 | Acc: 70.60% [ 50833.71/ 72000] | Train [14400/28709] in 57.260898s
Loss: 0.553976 | Acc: 70.97% [ 76645.54/108000] | Train [21600/28709] in 57.268075s
Loss: 0.555669 | Acc: 70.83% [101678.06/143545] | Train [28709/28709] in 56.668451s
Val Error: Acc 72.3% | Avg loss: 1.070889 in 18.770624s
Test Error: Acc 74.5% | Avg loss: 1.042726 in 18.732072s

Epoch 196, Learning Rate [4.6239994003080545e-05]
-------------------------------
Loss: 0.560945 | Acc: 70.45% [ 25360.28/ 36000] | Train [ 7200/28709] in 57.134263s
Loss: 0.559604 | Acc: 70.52% [ 50774.66/ 72000] | Train [14400/28709] in 57.276982s
Loss: 0.557750 | Acc: 70.70% [ 76357.68/108000] | Train [21600/28709] in 57.271671s
Loss: 0.557158 | Acc: 70.74% [101547.25/143545] | Train [28709/28709] in 56.784771s
Val Error: Acc 72.6% | Avg loss: 1.067199 in 19.012934s
Test Error: Acc 74.4% | Avg loss: 1.038632 in 18.772258s

Epoch 197, Learning Rate [2.9599073575926617e-05]
-------------------------------
Loss: 0.543080 | Acc: 72.09% [ 25951.85/ 36000] | Train [ 7200/28709] in 57.208570s
Loss: 0.547555 | Acc: 71.69% [ 51617.24/ 72000] | Train [14400/28709] in 57.335553s
Loss: 0.551330 | Acc: 71.39% [ 77102.00/108000] | Train [21600/28709] in 57.326276s
Loss: 0.551334 | Acc: 71.37% [102446.06/143545] | Train [28709/28709] in 56.734936s
Val Error: Acc 72.6% | Avg loss: 1.060955 in 18.791667s
Test Error: Acc 74.5% | Avg loss: 1.031530 in 18.736275s

Epoch 198, Learning Rate [1.6651875570451446e-05]
-------------------------------
Loss: 0.563383 | Acc: 70.12% [ 25244.93/ 36000] | Train [ 7200/28709] in 57.195038s
Loss: 0.557634 | Acc: 70.69% [ 50896.35/ 72000] | Train [14400/28709] in 57.330696s
Loss: 0.551925 | Acc: 71.36% [ 77064.36/108000] | Train [21600/28709] in 57.328786s
Loss: 0.552657 | Acc: 71.23% [102245.89/143545] | Train [28709/28709] in 56.721637s
Val Error: Acc 72.6% | Avg loss: 1.061337 in 18.781783s
Test Error: Acc 74.3% | Avg loss: 1.031817 in 18.754742s

Epoch 199, Learning Rate [7.401594514025999e-06]
-------------------------------
Loss: 0.540110 | Acc: 72.57% [ 26124.57/ 36000] | Train [ 7200/28709] in 57.187113s
Loss: 0.544513 | Acc: 72.14% [ 51940.83/ 72000] | Train [14400/28709] in 57.305708s
Loss: 0.543552 | Acc: 72.25% [ 78034.57/108000] | Train [21600/28709] in 57.305834s
Loss: 0.548522 | Acc: 71.73% [102960.48/143545] | Train [28709/28709] in 56.716146s
Val Error: Acc 72.4% | Avg loss: 1.059069 in 18.723832s
Test Error: Acc 74.4% | Avg loss: 1.027564 in 18.712058s

Epoch 200, Learning Rate [1.8505127750911841e-06]
-------------------------------
Loss: 0.553658 | Acc: 70.86% [ 25510.40/ 36000] | Train [ 7200/28709] in 57.176333s
Loss: 0.550744 | Acc: 71.32% [ 51353.32/ 72000] | Train [14400/28709] in 57.307993s
Loss: 0.555220 | Acc: 70.90% [ 76566.97/108000] | Train [21600/28709] in 57.308584s
Loss: 0.554846 | Acc: 70.97% [101872.80/143545] | Train [28709/28709] in 56.710609s
Val Error: Acc 72.4% | Avg loss: 1.058568 in 18.740192s
Test Error: Acc 74.6% | Avg loss: 1.029934 in 18.717188s
Done! with highest_accuracy: Val 0.730 | Test 0.749
